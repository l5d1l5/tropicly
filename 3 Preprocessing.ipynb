{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pyproj\n",
    "import logging\n",
    "import shapely\n",
    "import rasterio\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "from src.utils import get_data_dir\n",
    "from collections import defaultdict\n",
    "from src.decorators import benchmark\n",
    "from IPython.display import clear_output\n",
    "from rasterio import warp, merge, mask, windows, coords\n",
    "\n",
    "\n",
    "# Convenient access to data directory, is a namedtuple with folder names as attributes\n",
    "DIRS = get_data_dir(str(Path('data').resolve()))\n",
    "\n",
    "WGS84 = {'init': 'epsg:4326'}\n",
    "\n",
    "THREADLIMIT = 4\n",
    "\n",
    "# init Logging\n",
    "formater = logging.Formatter('%(asctime)s %(levelname)s: %(message)s', '%d/%m/%y %H:%M:%S')\n",
    "handler = logging.FileHandler(str(DIRS.log / 'preprocessing.log'), 'a+')\n",
    "handler.setLevel(logging.DEBUG)\n",
    "handler.setFormatter(formater)\n",
    "\n",
    "LOGGER = logging.getLogger('Preprocessing')\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "LOGGER.addHandler(handler)\n",
    "\n",
    "\n",
    "def read_raster(item):\n",
    "    \"\"\"\n",
    "    Helper method to return a raster file as a opened instance of\n",
    "    rasterio.io.DatasetReader in read mode.\n",
    "    \n",
    "    :param item: str, pathlib.Path or rasterio.io.DatasetReader\n",
    "        Should be the path to the raster file on filesystem as a string\n",
    "        or pathlib.Path object. If item is a instance of DatasetReader\n",
    "        the function returns immediately.\n",
    "    :return: rasterio.io.DatasetReader\n",
    "        Retruns an instance of rasterio.io.DatasetReader in read mode.\n",
    "    \"\"\"\n",
    "    if isinstance(item, rasterio.io.DatasetReader):\n",
    "        return item\n",
    "    else:\n",
    "        try:\n",
    "            path = str(item)  # Cast pathlib.Path to string\n",
    "            return rasterio.open(path, 'r')\n",
    "        except:\n",
    "            msg = 'Attr {}, Type {} is not a valid raster file'.format(item, type(item))\n",
    "            raise ValueError(msg)\n",
    "\n",
    "# TODO docstring\n",
    "def fetch_metadata(from_path_or_reader, *args):\n",
    "    \"\"\"\n",
    "    This method fetches user selected metadata features from a raster file and\n",
    "    returns them as a named tuple where the attribute name is the selected\n",
    "    metadata feature key and the assigned value the corresponding metadata\n",
    "    feature. Please refer to the documentation of rasterio for a comprehenisve \n",
    "    list of fetchable metadata features provided by a raster file.  \n",
    "    \n",
    "    :param from_path_or_reader: str, pathlib.Path or rasterio.io.DatasetReader\n",
    "        Path to the raster file on drive as string or pathlib.Path object or a\n",
    "        opened raster dataset.\n",
    "    :param *args: str\n",
    "        \n",
    "    :return: namedtuple\n",
    "        The requested metadata features as a namedtuple where the attribute \n",
    "        name is the selected metadata feature key and the assigned value the \n",
    "        corresponding metadata feature.\n",
    "        Example:\n",
    "        fetch_metadata(('bounds', 'crs'), path)\n",
    "        (bounds=value, crs=value)\n",
    "    \"\"\"\n",
    "    reader = read_raster(from_path_or_reader)\n",
    "    \n",
    "    values = []\n",
    "    for f in args:\n",
    "        value = reader.__getattribute__(f)\n",
    "        if value is not None:\n",
    "            values.append(value)\n",
    "        else:\n",
    "            raise ValueError('{} is not set'.format(f))\n",
    "    \n",
    "    # Closes the reader but if a user just want to proceed with the reader\n",
    "    # provided as arg this can be a pitfal\n",
    "    reader.close()\n",
    "    \n",
    "    if len(values) > 1:\n",
    "        Metadata = namedtuple('Metadata', args)\n",
    "        return Metadata(*values)\n",
    "    return values[0]\n",
    "\n",
    "\n",
    "def polygon_from(bounds):\n",
    "    \"\"\"\n",
    "    Creates a polygon object from a bounds object. \n",
    "    \n",
    "    :param bounds: namedtuple\n",
    "        Should be a namedtuple containing the attributes\n",
    "        left, right, top and bottom\n",
    "    :return: shapely.geometry.Polygon\n",
    "        The polygon object in extent of the provided bounds\n",
    "        object.\n",
    "    \"\"\"\n",
    "    x_points = ['left', 'left', 'right', 'right']\n",
    "    y_points = ['top', 'bottom', 'bottom', 'top']    \n",
    "    \n",
    "    polygon_bounds = [\n",
    "        (bounds.__getattribute__(x), bounds.__getattribute__(y))\n",
    "        for x, y in zip(x_points, y_points)\n",
    "    ]\n",
    "    \n",
    "    return shapely.geometry.Polygon(polygon_bounds)\n",
    "\n",
    "\n",
    "def reproject_bounds(bounds, source_crs, target_crs):\n",
    "    \"\"\"\n",
    "    This method reprojects the coordinates of an bounds object to the requested\n",
    "    coordinate system.\n",
    "    \n",
    "    :param bounds: namedtuple\n",
    "        Should be a namedtuple containing the attributes\n",
    "        left, right, top and bottom.\n",
    "    :param source_crs: dict\n",
    "        The coordinate reference system of the bounds object as a dictionary\n",
    "        with the following shape:\n",
    "        {'init': 'epsg:<id>'} where <id> is the epsg number of the crs \n",
    "    :param target_crs: dict\n",
    "        The coordinates system for the reprojection of the bounds object.\n",
    "        Shape should be equal to source_crs.\n",
    "    :return: namedtuple(left, right, top, bottom)\n",
    "        Reprojected bounds object\n",
    "    \"\"\"\n",
    "    p1 = pyproj.Proj(**source_crs)\n",
    "    p2 = pyproj.Proj(**target_crs)\n",
    "    \n",
    "    left, bottom = pyproj.transform(p1, p2, bounds.left, bounds.bottom)\n",
    "    right, top = pyproj.transform(p1, p2, bounds.right, bounds.top)\n",
    "    \n",
    "    BoundingBox = namedtuple('BoundingBox', 'left bottom right top')\n",
    "    return BoundingBox(left, bottom, right, top)\n",
    "\n",
    "\n",
    "# TODO docstring\n",
    "def polygoniz(rasters, target_crs):\n",
    "    \"\"\"\n",
    "    This function creates a tile index from a list of raster files.\n",
    "    \n",
    "    :param rasters: list\n",
    "        Pending\n",
    "    :param target_crs: dict\n",
    "        If the raster files have different coordinate reference systems\n",
    "        this arguement prevents a messed up dataset.\n",
    "    :return: geopandas.GeoSeries\n",
    "        Each element of the geoseries is a polygon\n",
    "        covering the corresponding raster file.\n",
    "    \"\"\"\n",
    "    polygons = []\n",
    "    for raster in rasters:\n",
    "        bounds, crs = fetch_metadata(raster, 'bounds', 'crs')\n",
    "        if crs != target_crs:\n",
    "            bounds = reproject_bounds(bounds, crs, target_crs)\n",
    "        polygon = polygon_from(bounds)\n",
    "        polygons.append(polygon)\n",
    "        \n",
    "    geometry = gpd.GeoSeries(polygons)\n",
    "    geometry.crs = target_crs\n",
    "    return geometry\n",
    "\n",
    "\n",
    "# TODO docstring\n",
    "def tile_index(rasters, target_crs, **kwargs):\n",
    "    \"\"\"\n",
    "    Description Pending\n",
    "    \n",
    "    :param rasters: list\n",
    "        A list of str where each element is a path to a raster file\n",
    "        on disk.\n",
    "    :param target_crs: dict\n",
    "        The coordinate reference system which should be applied on\n",
    "        the tile index dataset.\n",
    "    :param **kwargs:\n",
    "    :return: geopandas.GeoDataFrame\n",
    "    \"\"\"\n",
    "    geometry = polygoniz(rasters, target_crs)\n",
    "    features = pd.DataFrame(kwargs)\n",
    "    \n",
    "    return gpd.GeoDataFrame(features, geometry=geometry)\n",
    "\n",
    "\n",
    "# TODO accept **kwargs to alter write parameters docstring\n",
    "def reproject_from(in_path, to_crs, out_path):\n",
    "    \"\"\"\n",
    "    This method reprojects a raster file to a selected coordinate\n",
    "    reference system.\n",
    "    \n",
    "    :param in_path: str\n",
    "        Path to raster file on drive\n",
    "    :param to_crs: dict\n",
    "        Target coordinate reference system for reprojection\n",
    "    :param out_path: str\n",
    "        Path where the reprojected raster file should be stored\n",
    "    :return: str\n",
    "        Path where the reprojected raster file is stored\n",
    "    \"\"\"\n",
    "    with rasterio.open(in_path, 'r') as src:\n",
    "        affine, width, height = rasterio.warp.calculate_default_transform(\n",
    "            src_crs=src.crs,\n",
    "            dst_crs=to_crs,\n",
    "            width=src.width,\n",
    "            height=src.height,\n",
    "            **src.bounds._asdict(),\n",
    "        )\n",
    "        \n",
    "        kwargs = src.profile.copy()\n",
    "        kwargs.update(\n",
    "            transform=affine,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            crs=to_crs\n",
    "        )\n",
    "        \n",
    "        with rasterio.open(out_path, 'w', **kwargs) as dst:\n",
    "            for idx in src.indexes:\n",
    "                rasterio.warp.reproject(\n",
    "                    source=rasterio.band(src, idx), \n",
    "                    destination=rasterio.band(dst, idx)\n",
    "                )\n",
    "        \n",
    "        return out_path\n",
    "\n",
    "\n",
    "# TODO docstring\n",
    "def reproject_like(template, in_path, out_path: str):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    crs, transform, width, height = fetch_metadata(template, 'crs', 'transform', 'width', 'height')\n",
    "    \n",
    "    with rasterio.open(in_path, 'r') as src:\n",
    "        out_kwargs = src.profile.copy()\n",
    "        out_kwargs.update({\n",
    "            'crs': crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(out_path, 'w', **out_kwargs) as dst:\n",
    "            rasterio.warp.reproject(source=rasterio.band(src, list(range(1, src.count + 1))), \n",
    "                                    destination=rasterio.band(dst, list(range(1, src.count + 1))))\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "\n",
    "def merge_from(rasters, **kwargs):\n",
    "    \"\"\"\n",
    "    Merges a list of raster files to one single raster dataset.\n",
    "    This method is wrapped around the rasterio.merge.merge method\n",
    "    therefore this method accept keyword arguments as well.\n",
    "    \n",
    "    :param rasters: list\n",
    "        A list of strings or pathlib.Path objects where each list element reference a path to a\n",
    "        raster file on drive.\n",
    "    :param **kwargs:\n",
    "        Please refer to the rasterio documentation for a full list\n",
    "        of possible keyword arguments.\n",
    "    :return: namedtuple(data, affine)\n",
    "        A namedtuple with the attributes data and affine, where the parameter\n",
    "        data contains the merged data of the raster files as a numpy.ndarray \n",
    "        and affine an affine transformation matrix.\n",
    "    \"\"\"\n",
    "    readers = [read_raster(raster) for raster in rasters]\n",
    "\n",
    "    dest, affine = rasterio.merge.merge(readers, **kwargs)\n",
    "    \n",
    "    [reader.close() for reader in readers]\n",
    "    Merge = namedtuple('Merge', 'data affine')  \n",
    "    return Merge(dest, affine)\n",
    "\n",
    "\n",
    "def merge_alike(with_template, to_merge):\n",
    "    \"\"\"\n",
    "    Merges the input raster files like a template raster, hence the output\n",
    "    dataset has same bounds and resolution as the template raster. Both datasets\n",
    "    must have the same coordinate reference system.\n",
    "    \n",
    "    :param with_template: str\n",
    "        Path to the template raster file\n",
    "    :param to_merge: list\n",
    "        A list of strings where each list element reference a path to a\n",
    "        raster file on drive.\n",
    "    :return: namedtuple(data, affine)\n",
    "        A namedtuple with the attributes data and affine, where the parameter\n",
    "        data contains the merged data of the raster files as a numpy.ndarray \n",
    "        and affine an affine transformation matrix.\n",
    "    \"\"\"\n",
    "    bounds, res = fetch_metadata(with_template, 'bounds', 'res')\n",
    "    return merge_from(to_merge, bounds=bounds, res=res)\n",
    "\n",
    "\n",
    "def write(data, to_path, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes a multi-dimensional numpy.ndarray as a raster dataset to file.\n",
    "    This method is wrapped around the rasterio.open method therefore \n",
    "    you can modify the methods behavior  with **kwargs arguements provided\n",
    "    by the rasterio documentation.\n",
    "    \n",
    "    :param data: numpy.ndarray\n",
    "        A multi-dimensional numpy array. If array has three dimensions\n",
    "        each dimension depict a raster band. If array has two dimensions\n",
    "        the resulting raster file contains a sinlge band.\n",
    "    :param to_path: str\n",
    "        Path where the new raster file should be stored\n",
    "    :param **kwargs:\n",
    "        Keyword arguments consumed by the rasterio.open function.\n",
    "        Please refer to the rasterio documentation for a comprehensive\n",
    "        list of possible keyword arguements.\n",
    "    :return: str\n",
    "        Path where the raster file is stored \n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        idx, height, width = data.shape  # z, y, x\n",
    "    elif len(data.shape) == 2:\n",
    "        idx = 1  # z\n",
    "        height, width = data.shape  # y, x\n",
    "        data = np.reshape(data.copy(), (idx, height, width))\n",
    "    else:\n",
    "        raise ValueError('Please, provide a valid dataset')\n",
    "    \n",
    "    dtype = data.dtype\n",
    "    kwargs.update(\n",
    "        count=idx,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        dtype=dtype\n",
    "    )\n",
    "    \n",
    "    with rasterio.open(to_path, 'w', **kwargs) as dst:\n",
    "        for i in range(idx):\n",
    "            dst.write(data[i], i+1)  # rasterio band index start at one, thus we increment by one\n",
    "    \n",
    "    return to_path\n",
    "\n",
    "\n",
    "def int_to_orient(x, y):\n",
    "    \"\"\"\n",
    "    Converts a x- and y-coordinate to an integer north/south,\n",
    "    weste/east string representation.\n",
    "    Example: (x=-179.3457, y=80.2222) -> 80N_179W\n",
    "             \n",
    "    :param x: float\n",
    "        Longitudinal coordinate  \n",
    "    :param y: float\n",
    "        Latitudinal coordinate \n",
    "    :return: str\n",
    "        Lat/Lon coordinates as a integer string with the according\n",
    "        orientation.\n",
    "    \"\"\"\n",
    "    x = round(x)\n",
    "    y = round(y)\n",
    "    \n",
    "    lng, we = (-1 * x, 'W') if x < 0 else (x, 'E')\n",
    "    lat, ns = (-1 * y, 'S') if y < 0 else (y, 'N')\n",
    "    \n",
    "    return '{:02d}{}_{:03d}{}'.format(lat, ns, lng, we)\n",
    "\n",
    "\n",
    "# TODO docstring\n",
    "def round_bounds(bounds):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    attrs = ('left', 'bottom', 'right', 'top')\n",
    "    \n",
    "    coords = []\n",
    "    for attr in attrs:\n",
    "        coord = bounds.__getattribute__(attr)\n",
    "        coords.append(round(coord))\n",
    "    \n",
    "    BoundingBox = namedtuple('BoundingBox', attrs)\n",
    "    return BoundingBox(*coords)\n",
    "\n",
    "\n",
    "# TODO docstring\n",
    "def clip_raster(raster, dst_bounds):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    src = read_raster(raster)\n",
    "    src_bounds = src.bounds\n",
    "    \n",
    "    if coords.disjoint_bounds(src_bounds, dst_bounds):\n",
    "        msg = 'Raster bounds {} are not covered by clipping bounds {}'.format(src_bounds, dst_bounds)\n",
    "        raise ValueError(msg)\n",
    "    \n",
    "    window = src.window(*dst_bounds)\n",
    "    window = window.round_lengths(op='ceil')\n",
    "    transform = src.window_transform(window)\n",
    "    data = src.read(window=window, out_shape=(src.count, window.height, window.width))\n",
    "    \n",
    "    src.close()\n",
    "    return data, transform\n",
    "\n",
    "\n",
    "# TODO refactor rename to dispatch_filename docstring\n",
    "def dispatch_name(val, key, idx):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'merge_0': lambda: ('cover', '{}_{}.tif'.format(idx, key)),\n",
    "        'merge_1': lambda: ('loss', '{}_{}.tif'.format(idx, key)),\n",
    "        'merge_2': lambda: ('gain', '{}_{}.tif'.format(idx, key)),\n",
    "        'merge_3': lambda: ('biomass', '{}_{}.tif'.format(idx, key)),\n",
    "        'merge_4': lambda: ('confidence', '{}_{}.tif'.format(idx, key)),\n",
    "        'reproject_0': lambda: ('gl30_10', '{}_{}.tif'.format(idx, key)),\n",
    "        'reproject_1': lambda: ('gl30_00', '{}_{}.tif'.format(idx, key)),\n",
    "        'reproject_2': lambda: ('soil', '{}_{}.tif'.format(idx, key)),\n",
    "    }.get(val, None)()\n",
    "\n",
    "\n",
    "# TODO docstring\n",
    "def dispatch_range(key, value):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'cover': lambda: not 0 <= value <= 100, # union should be not greater than 101\n",
    "        'loss': lambda: not 0 <= value <= 12, # union should be not greater than 13\n",
    "        'gain': lambda: not 0 <= value <= 1,  # union should be not greater than two\n",
    "        'biomass': lambda: not -32768 <= value <= 1000,\n",
    "        'confidence': lambda: None,\n",
    "        'soil': lambda: None,\n",
    "        'gl30_00': lambda: not 0 <= value <= 255,\n",
    "        'gl30_10': lambda: not 0 <= value <= 255 ,\n",
    "    }.get(key, lambda: False)()\n",
    "\n",
    "\n",
    "# TODO docstring\n",
    "def test_bounds_are_equal(datasets):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    bounds = fetch_metadata(datasets[0][1], 'bounds') \n",
    "    data_bounds = [fetch_metadata(item[1], 'bounds') for item in datasets]\n",
    "\n",
    "    for idx, db in enumerate(data_bounds):\n",
    "        if bounds != db:\n",
    "            msg = '\"{}\" inequal bounds \"{} != {}\"'.format(datasets[idx].name, db, bounds)\n",
    "            LOGGER.warning(msg)\n",
    "\n",
    "\n",
    "# TODO docstring\n",
    "# broken\n",
    "# set operation intersection length = 0 non overlap\n",
    "def test_expected_valuerange(key, dataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    raster = read_raster(dataset)\n",
    "    values = np.unique(raster.read())\n",
    "    raster.close()\n",
    "    \n",
    "    for val in values:\n",
    "        if dispatch_range(key, val):\n",
    "            msg = '\"{}\" with range \"{}\" is not expected range for \"{}\"'.format(dataset.name, values, key)\n",
    "            LOGGER.warning(msg)\n",
    "\n",
    "\n",
    "def test_expected_metadata():\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_landmass_overlapping():\n",
    "    pass\n",
    "\n",
    "\n",
    "# TODO refactor and docstring\n",
    "def worker(to_reproject: list, to_crs: dict, to_merge_alike: list, out_path: str, generic_name: str):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    template = None\n",
    "    path = Path(out_path)\n",
    "    \n",
    "    for idx, raster in enumerate(to_reproject):\n",
    "        opath = str(path / 'reproject_{}_{}'.format(idx, generic_name))\n",
    "        \n",
    "        if idx == 0:\n",
    "            try:\n",
    "                template = reproject_from(raster, to_crs, opath)\n",
    "            except Exception as err:\n",
    "                LOGGER.error('Fatal no template %s', raster, exc_info=err)\n",
    "                raise err\n",
    "        else:\n",
    "            try:\n",
    "                reproject_like(template, raster, opath)\n",
    "            except Exception as err:\n",
    "                LOGGER.warning('Unable to reproject %s', raster, exc_info=err)\n",
    "                    \n",
    "    kwargs = fetch_metadata(template, 'profile')\n",
    "    \n",
    "    for idx, rasters in enumerate(to_merge_alike):\n",
    "        opath = str(path / 'merge_{}_{}'.format(idx, generic_name))       \n",
    "        try:\n",
    "            data, transform = merge_alike(template, rasters)\n",
    "            kwargs.update({'transform': transform})\n",
    "            write(data, opath, **kwargs)\n",
    "        except Exception as err:\n",
    "            LOGGER.warning('Unable to merge %s, cant create %s', rasters, opath)\n",
    "            \n",
    "\n",
    "# TODO refactor and docstring        \n",
    "def clip_worker(to_clip: list, bounds: namedtuple, profile: dict, out_path: str):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    key = int_to_orient(bounds.left, bounds.top)\n",
    "    path = Path(out_path)\n",
    "    \n",
    "    for idx, raster in enumerate(to_clip):\n",
    "        data, transform = clip_raster(raster, bounds)\n",
    "        opath = path / '{}_{}.tif'.format(idx, key)\n",
    "        profile.update({'transform': transform})\n",
    "        write(data, str(opath), **profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFC mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cover</th>\n",
       "      <th>gain</th>\n",
       "      <th>loss</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_000E.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_000E.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_000E.tif</td>\n",
       "      <td>POLYGON ((-0.0001388888888982365 0.00013888888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_010E.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_010E.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_010E.tif</td>\n",
       "      <td>POLYGON ((9.999861111111102 0.0001388888888840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_010W.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_010W.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_010W.tif</td>\n",
       "      <td>POLYGON ((-10.0001388888889 0.0001388888888840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_020E.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_020E.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_020E.tif</td>\n",
       "      <td>POLYGON ((19.9998611111111 0.00013888888888402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_020W.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_020W.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_020W.tif</td>\n",
       "      <td>POLYGON ((-20.0001388888889 0.0001388888888840...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       cover  \\\n",
       "0  Hansen_GFC2013_treecover2000_00N_000E.tif   \n",
       "1  Hansen_GFC2013_treecover2000_00N_010E.tif   \n",
       "2  Hansen_GFC2013_treecover2000_00N_010W.tif   \n",
       "3  Hansen_GFC2013_treecover2000_00N_020E.tif   \n",
       "4  Hansen_GFC2013_treecover2000_00N_020W.tif   \n",
       "\n",
       "                               gain                                  loss  \\\n",
       "0  Hansen_GFC2013_gain_00N_000E.tif  Hansen_GFC2013_lossyear_00N_000E.tif   \n",
       "1  Hansen_GFC2013_gain_00N_010E.tif  Hansen_GFC2013_lossyear_00N_010E.tif   \n",
       "2  Hansen_GFC2013_gain_00N_010W.tif  Hansen_GFC2013_lossyear_00N_010W.tif   \n",
       "3  Hansen_GFC2013_gain_00N_020E.tif  Hansen_GFC2013_lossyear_00N_020E.tif   \n",
       "4  Hansen_GFC2013_gain_00N_020W.tif  Hansen_GFC2013_lossyear_00N_020W.tif   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-0.0001388888888982365 0.00013888888...  \n",
       "1  POLYGON ((9.999861111111102 0.0001388888888840...  \n",
       "2  POLYGON ((-10.0001388888889 0.0001388888888840...  \n",
       "3  POLYGON ((19.9998611111111 0.00013888888888402...  \n",
       "4  POLYGON ((-20.0001388888889 0.0001388888888840...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfc = sorted(DIRS.gfc.glob('*.tif'))\n",
    "\n",
    "data_len = int(len(gfc)/3)\n",
    "\n",
    "kwargs = {\n",
    "    'gain': [i.name for i in gfc[:data_len]],\n",
    "    'loss': [i.name for i in gfc[data_len:2*data_len]],\n",
    "    'cover': [i.name for i in gfc[2*data_len:]],\n",
    "}\n",
    "\n",
    "gfc_mask = tile_index(gfc[:data_len], WGS84, **kwargs)\n",
    "gfc_mask.to_file(str(DIRS.masks / 'gfc_mask.shp'))\n",
    "gfc_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GL30 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gl30_00</th>\n",
       "      <th>gl30_10</th>\n",
       "      <th>key</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02_15_2000lc030.tif</td>\n",
       "      <td>n02_15_2010lc030.tif</td>\n",
       "      <td>n02_15</td>\n",
       "      <td>POLYGON ((-174.0053601744084 20.00401663536249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n03_05_2000lc030.tif</td>\n",
       "      <td>n03_05_2010lc030.tif</td>\n",
       "      <td>n03_05</td>\n",
       "      <td>POLYGON ((-168.0054833302891 10.00519024901941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n03_20_2000lc030.tif</td>\n",
       "      <td>n03_20_2010lc030.tif</td>\n",
       "      <td>n03_20</td>\n",
       "      <td>POLYGON ((-168.0051433812486 25.00312959291788...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n04_00_2000lc030.tif</td>\n",
       "      <td>n04_00_2010lc030.tif</td>\n",
       "      <td>n04_00</td>\n",
       "      <td>POLYGON ((-162.0055192236557 5.005478418984219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n04_05_2000lc030.tif</td>\n",
       "      <td>n04_05_2010lc030.tif</td>\n",
       "      <td>n04_05</td>\n",
       "      <td>POLYGON ((-162.0054833302891 10.0051902490194,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gl30_00               gl30_10     key  \\\n",
       "0  n02_15_2000lc030.tif  n02_15_2010lc030.tif  n02_15   \n",
       "1  n03_05_2000lc030.tif  n03_05_2010lc030.tif  n03_05   \n",
       "2  n03_20_2000lc030.tif  n03_20_2010lc030.tif  n03_20   \n",
       "3  n04_00_2000lc030.tif  n04_00_2010lc030.tif  n04_00   \n",
       "4  n04_05_2000lc030.tif  n04_05_2010lc030.tif  n04_05   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-174.0053601744084 20.00401663536249...  \n",
       "1  POLYGON ((-168.0054833302891 10.00519024901941...  \n",
       "2  POLYGON ((-168.0051433812486 25.00312959291788...  \n",
       "3  POLYGON ((-162.0055192236557 5.005478418984219...  \n",
       "4  POLYGON ((-162.0054833302891 10.0051902490194,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl30 = sorted(DIRS.gl30.glob('*.tif'), key=lambda key: (key.name[7:11], key.name[0:6]))\n",
    "\n",
    "exclude = 'n01_00 s01_00 s01_10 s01_15 s01_20 s60_00 s60_05 s60_10 s60_15 n53_00'.split()\n",
    "gl30 = [item for item in gl30 if item.name[0:6] not in exclude]\n",
    "data_len = int(len(gl30)/2)\n",
    "\n",
    "kwargs = {\n",
    "    'gl30_00': [i.name for i in gl30[:data_len]],\n",
    "    'gl30_10': [i.name for i in gl30[data_len:]],\n",
    "    'key': [i.name[0:6] for i in gl30[:data_len]]\n",
    "}\n",
    "\n",
    "gl30_mask = tile_index(gl30[data_len:], WGS84, **kwargs)\n",
    "gl30_mask.to_file(str(DIRS.masks / 'gl30_mask.shp'))\n",
    "gl30_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biomass mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biomass</th>\n",
       "      <th>confidence</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10N_090W_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_10N_090W.tif</td>\n",
       "      <td>POLYGON ((-90.0001388885744 0.0001388894243932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10N_050E_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_10N_050E.tif</td>\n",
       "      <td>POLYGON ((49.9998611109019 7.999861110840482, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10S_170E_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_10S_170E.tif</td>\n",
       "      <td>POLYGON ((169.9998611109663 -12.00013888921919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20N_100W_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_20N_100W.tif</td>\n",
       "      <td>POLYGON ((-100.0001388891786 13.00013888876461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20S_020E_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_20S_020E.tif</td>\n",
       "      <td>POLYGON ((19.99986111088579 -29.99986111075941...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              biomass                             confidence  \\\n",
       "0  10N_090W_merge.tif  merged_per_tropical_asia_10N_090W.tif   \n",
       "1  10N_050E_merge.tif  merged_per_tropical_asia_10N_050E.tif   \n",
       "2  10S_170E_merge.tif  merged_per_tropical_asia_10S_170E.tif   \n",
       "3  20N_100W_merge.tif  merged_per_tropical_asia_20N_100W.tif   \n",
       "4  20S_020E_merge.tif  merged_per_tropical_asia_20S_020E.tif   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-90.0001388885744 0.0001388894243932...  \n",
       "1  POLYGON ((49.9998611109019 7.999861110840482, ...  \n",
       "2  POLYGON ((169.9998611109663 -12.00013888921919...  \n",
       "3  POLYGON ((-100.0001388891786 13.00013888876461...  \n",
       "4  POLYGON ((19.99986111088579 -29.99986111075941...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biomass = gpd.read_file(str(DIRS.masks / 'biomass.geojson'))\n",
    "biomass_mask = biomass.drop(biomass.columns[[0, 1, 4, 5]], axis=1)\n",
    "biomass_mask.rename(columns={'download': 'biomass'}, inplace=True)\n",
    "\n",
    "for idx, row in biomass_mask.iterrows():\n",
    "    biomass = row.biomass.split('/')[-1]\n",
    "    confidence = row.confidence.split('/')[-1]\n",
    "    \n",
    "    biomass_mask.at[idx, 'biomass'] = biomass\n",
    "    biomass_mask.at[idx, 'confidence'] = confidence\n",
    "\n",
    "biomass_mask.to_file(str(DIRS.masks / 'biomass_mask.shp'))\n",
    "biomass_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster alignment\n",
    "- include soil layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gl30_mask = gpd.read_file(str(DIRS.masks / 'gl30_mask.shp'))\n",
    "gfc_mask = gpd.read_file(str(DIRS.masks / 'gfc_mask.shp'))\n",
    "biomass_mask = gpd.read_file(str(DIRS.masks / 'biomass_mask.shp'))\n",
    "\n",
    "intersect = gpd.overlay(gfc_mask, gl30_mask, how='intersection')\n",
    "intersect = gpd.overlay(intersect, biomass_mask, how='intersection')\n",
    "\n",
    "threads = []\n",
    "for key, values in intersect.groupby(by='key', sort=False):\n",
    "    if len(threads) == THREADLIMIT:\n",
    "        [thread.join() for thread in threads]\n",
    "        threads = []\n",
    "    \n",
    "    to_reproject = [\n",
    "        str(DIRS.gl30 / name)\n",
    "        for name in list(*zip(set(values.gl30_10), set(values.gl30_00)))\n",
    "    ]\n",
    "    to_reproject.append(str(DIRS.soil / 'GSOCmapV1.1.tif'))\n",
    "    to_merge = [\n",
    "        [str(DIRS.gfc / name) for name in set(values.cover)],\n",
    "        [str(DIRS.gfc / name) for name in set(values.loss)],\n",
    "        [str(DIRS.gfc / name) for name in set(values.gain)],\n",
    "        [str(DIRS.biomass / name) for name in set(values.biomass)],\n",
    "        [str(DIRS.biomass / name) for name in set(values.confidence)],\n",
    "    ]\n",
    "    generic_name = '{}.tif'.format(key)\n",
    "    \n",
    "    thread = threading.Thread(target=worker,\n",
    "                              args=(to_reproject, WGS84, to_merge, str(DIRS.proc), generic_name))\n",
    "    thread.start()\n",
    "    threads.append(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Croping and masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = defaultdict(list)\n",
    "regex = re.compile(r'.*(?P<key>(?:n|s)\\d{2}_\\d{2}).*', re.I)\n",
    "\n",
    "for path in DIRS.proc.glob('*.tif'):\n",
    "    match = regex.match(str(path))\n",
    "    files[match.group('key')].append(path)\n",
    "    files[match.group('key')] = sorted(files[match.group('key')])\n",
    "\n",
    "threads = []\n",
    "features = []\n",
    "polygons = []\n",
    "length = len(files)\n",
    "idx = 0\n",
    "for key, values in files.items():\n",
    "    if len(threads) == THREADLIMIT:\n",
    "        clear_output()\n",
    "        \n",
    "        [thread.join() for thread in threads]\n",
    "        threads = []\n",
    "        \n",
    "        ratio = round((idx / length) * 100, 2)\n",
    "        print('Processed {} % of {} %'.format(ratio, 100))\n",
    "    \n",
    "    bounds, profile = fetch_metadata(values[0], 'bounds', 'profile')\n",
    "    bounds = round_bounds(bounds)\n",
    "\n",
    "    thread = threading.Thread(target=clip_worker, args=(values, bounds, profile, str(DIRS.proc),))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "    key = int_to_orient(bounds.left, bounds.top)\n",
    "    feature = dict([dispatch_name('{0[0]}_{0[1]}'.format(item.name.split('_')), key, idx)\n",
    "                    for idx, item in enumerate(values)])\n",
    "    feature['key'] = key\n",
    "    features.append(feature)\n",
    "    polygons.append(polygon_from(bounds))\n",
    "    \n",
    "    idx += 1\n",
    "\n",
    "geometry = gpd.GeoSeries(polygons)\n",
    "df = pd.DataFrame(features)\n",
    "layer = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "layer.crs = WGS84\n",
    "\n",
    "layer.to_file(str(DIRS.masks / 'final_mask.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cover /media/ilex/StorageOne/docs/code/python/projects/Master/data/proc/3_20S_048W.tif\n",
      "cover /media/ilex/StorageOne/docs/code/python/projects/Master/data/proc/0_20S_048W.tif\n",
      "cover /media/ilex/StorageOne/docs/code/python/projects/Master/data/proc/2_20S_048W.tif\n",
      "cover /media/ilex/StorageOne/docs/code/python/projects/Master/data/proc/5_20S_048W.tif\n",
      "cover /media/ilex/StorageOne/docs/code/python/projects/Master/data/proc/4_20S_048W.tif\n",
      "cover /media/ilex/StorageOne/docs/code/python/projects/Master/data/proc/1_20S_048W.tif\n"
     ]
    }
   ],
   "source": [
    "# BUGS\n",
    "final_mask = gpd.read_file(str(DIRS.masks / 'final_mask.shp'))\n",
    "columns = final_mask.columns[:-1]\n",
    "\n",
    "for idx, vals in final_mask.iterrows():\n",
    "    gen = filter(lambda x: x[1].split('.')[-1] == 'tif', zip(columns, vals[:-1]))\n",
    "    data = [(key, DIRS.proc / path) for key, path in gen]\n",
    "\n",
    "    test_bounds_are_equal(data)\n",
    "    [test_expected_valuerange('cover', path) for key, path in data]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "lit.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
