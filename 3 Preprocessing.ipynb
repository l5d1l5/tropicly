{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import queue\n",
    "import pyproj\n",
    "import shapely\n",
    "import rasterio\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from src.utils import get_data_dir\n",
    "from src.decorators import benchmark\n",
    "from collections import namedtuple\n",
    "from rasterio import warp, merge\n",
    "\n",
    "\n",
    "# Convenient access to data directory, is a namedtuple with folder names as attributes\n",
    "DIRS = get_data_dir(str(Path('data').resolve()))\n",
    "\n",
    "# Processing pipeline coordinates system\n",
    "WGS84 = {'init': 'epsg:4326'}\n",
    "\n",
    "# Many functions of the processing pipeline are multi-threaded this attribute controls\n",
    "# max number of threads\n",
    "THREADLIMIT = 12\n",
    "\n",
    "\n",
    "def read_raster(item) -> rasterio.io.DatasetReader:\n",
    "    \"\"\"\n",
    "    Helper method to return a raster file as a opened instance of\n",
    "    rasterio.io.DatasetReader in read mode. Throws a exception if\n",
    "    raster file is not openable with the assigned file system handle.\n",
    "    \n",
    "    :param item: str, pathlib.Path or rasterio.io.DatasetReader\n",
    "        Should be the path to the raster file on filesystem as a string\n",
    "        or pathlib.Path object. If item is a instance of DatasetReader\n",
    "        the function returns immediately.\n",
    "    :return: rasterio.io.DatasetReader\n",
    "        Retruns an instance of rasterio.io.DatasetReader in read mode.\n",
    "    \"\"\"\n",
    "    if isinstance(item, rasterio.io.DatasetReader):\n",
    "        return item\n",
    "    else:\n",
    "        try:\n",
    "            path = str(item)  # Cast pathlib.Path to string\n",
    "            return rasterio.open(path, 'r')\n",
    "        except:\n",
    "            msg = 'Attr {}, Type {} is not a valid raster file'.format(item, type(item))\n",
    "            raise ValueError(msg)\n",
    "\n",
    "\n",
    "def fetch_metadata(features: list, from_path_or_reader: str) -> namedtuple:\n",
    "    \"\"\"\n",
    "    This method fetches user selected metadata features from a raster file and\n",
    "    returns them as a named tuple where the attribute name is the selected\n",
    "    metadata feature key and the assigned value the corresponding metadata\n",
    "    feature. Please refer to the documentation of rasterio for a comprehenisve \n",
    "    list of fetchable metadata features provided by a raster file.  \n",
    "    \n",
    "    :param features: list or tuple of str\n",
    "        The requested metadata feature as a list or tuple of strings.\n",
    "    :param from_path_or_reader: str, pathlib.Path or rasterio.io.DatasetReader\n",
    "        Path to the raster file on drive as string or pathlib.Path object or a\n",
    "        opened raster dataset.\n",
    "    :return: namedtuple\n",
    "        The requested metadata features as a namedtuple where the attribute \n",
    "        name is the selected metadata feature key and the assigned value the \n",
    "        corresponding metadata feature.\n",
    "        Example:\n",
    "        fetch_metadata(('bounds', 'crs'), path)\n",
    "        (bounds=value, crs=value)\n",
    "    \"\"\"\n",
    "    reader = read_raster(from_path_or_reader)\n",
    "    \n",
    "    values = []\n",
    "    for f in features:\n",
    "        value = reader.__getattribute__(f)\n",
    "        if value is not None:\n",
    "            values.append(value)\n",
    "        else:\n",
    "            raise ValueError('{} is not set'.format(f))\n",
    "    \n",
    "    # Closes the reader but if a user just want to proceed with the reader\n",
    "    # provided as arg this can be a pitfal\n",
    "    reader.close()\n",
    "    Metadata = namedtuple('Metadata', features)\n",
    "    return Metadata(*values)\n",
    "\n",
    "\n",
    "# TODO refactor to def(left, right, top, y2)\n",
    "def polygon_from(bounds: namedtuple) -> shapely.geometry.Polygon:\n",
    "    \"\"\"\n",
    "    Creates a polygon obeject from a bounds object. \n",
    "    \n",
    "    :param bounds: namedtuple\n",
    "        Should be a namedtuple comprising the attributes\n",
    "        left, right, top and bottom.\n",
    "    :return: shapely.geometry.Polygon\n",
    "        The polygon object in extent of the provided bounds\n",
    "        object.\n",
    "    \"\"\"\n",
    "    x_points = ['left', 'left', 'right', 'right']\n",
    "    y_points = ['top', 'bottom', 'bottom', 'top']    \n",
    "    \n",
    "    polygon_bounds = [\n",
    "        (bounds.__getattribute__(x), bounds.__getattribute__(y))\n",
    "        for x, y in zip(x_points, y_points)\n",
    "    ]\n",
    "    \n",
    "    return shapely.geometry.Polygon(polygon_bounds)\n",
    "\n",
    "\n",
    "def reproject_bounds(bounds: namedtuple, source_crs: dict, target_crs: dict) -> namedtuple:\n",
    "    \"\"\"\n",
    "    This method reprojects the coordinates of an bounds object to the requested\n",
    "    coordinate system.\n",
    "    \n",
    "    :param bounds: namedtuple\n",
    "        Should be a namedtuple containing the attributes\n",
    "        left, right, top and bottom.\n",
    "    :param source_crs: dict\n",
    "        The coordinate reference system of the bounds object as a dictionary\n",
    "        with the following shape:\n",
    "        {'init': 'epsg:<id>'} where <id> is the epsg number of the crs \n",
    "    :param target_crs: dict\n",
    "        The coordinates system for the reprojection of the bounds object.\n",
    "        Shape should be equal to source_crs.\n",
    "    :return: namedtuple(left, right, top, bottom)\n",
    "        Reprojected bounds object\n",
    "    \"\"\"\n",
    "    p1 = pyproj.Proj(**source_crs)\n",
    "    p2 = pyproj.Proj(**target_crs)\n",
    "    \n",
    "    left, bottom = pyproj.transform(p1, p2, bounds.left, bounds.bottom)\n",
    "    right, top = pyproj.transform(p1, p2, bounds.right, bounds.top)\n",
    "    \n",
    "    BoundingBox = namedtuple('BoundingBox', 'left bottom right top')\n",
    "    return BoundingBox(left, bottom, right, top)\n",
    "\n",
    "\n",
    "def polygoniz(paths_or_readers: list, target_crs: dict) -> gpd.GeoSeries:\n",
    "    \"\"\"\n",
    "    This function creates a tile index from a set of raster files.\n",
    "    \n",
    "    :param path_or_readers: list\n",
    "        Pending\n",
    "    :param target_crs: dict\n",
    "        If the raster files have different coordinate reference systems\n",
    "        this arguement prevents a messed up dataset.\n",
    "    :return: geopandas.GeoSeries\n",
    "        Each element of the geoseries is a polygon\n",
    "        covering the corresponding raster file.\n",
    "    \"\"\"\n",
    "    polygons = []\n",
    "    for item in paths_or_readers:\n",
    "        bounds, crs = fetch_metadata(('bounds', 'crs'), item)\n",
    "        if crs != target_crs:\n",
    "            bounds = reproject_bounds(bounds, crs, target_crs)\n",
    "        polygon = polygon_from(bounds)\n",
    "        polygons.append(polygon)\n",
    "        \n",
    "    geometry = gpd.GeoSeries(polygons)\n",
    "    geometry.crs = target_crs\n",
    "    return geometry\n",
    "\n",
    "\n",
    "def tile_index(rasters: list, target_crs: dict, **kwargs) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Description Pending\n",
    "    \n",
    "    :param rasters: list\n",
    "        A list of str where each element is a path to a raster file\n",
    "        on disk.\n",
    "    :param target_crs: dict\n",
    "        The coordinate reference system which should be applied on\n",
    "        the tile index dataset.\n",
    "    :param **kwargs:\n",
    "    :return: geopandas.GeoDataFrame\n",
    "    \"\"\"\n",
    "    geometry = polygoniz(rasters, target_crs)\n",
    "    features = pd.DataFrame(kwargs)\n",
    "    \n",
    "    return gpd.GeoDataFrame(features, geometry=geometry)\n",
    "\n",
    "\n",
    "# TODO accept **kwargs to alter write parameters\n",
    "def reproject_from(in_path: str, to_crs: dict, to_out_path: str):\n",
    "    \"\"\"\n",
    "    This method reprojects a raster file to a selected coordinate\n",
    "    reference system.\n",
    "    \n",
    "    :param in_path: str\n",
    "        Path to raster file on drive\n",
    "    :param to_crs: dict\n",
    "        Target coordinate reference system for reprojection\n",
    "    :param to_out_path: str\n",
    "        Path where the reprojected raster file should be stored\n",
    "    :return: str\n",
    "        Path where the reprojected raster file is stored\n",
    "    \"\"\"\n",
    "    with rasterio.open(in_path, 'r') as src:\n",
    "        affine, width, height = rasterio.warp.calculate_default_transform(\n",
    "            src_crs=src.crs,\n",
    "            dst_crs=to_crs,\n",
    "            width=src.width,\n",
    "            height=src.height,\n",
    "            **src.bounds._asdict(),\n",
    "        )\n",
    "        \n",
    "        kwargs = src.profile.copy()\n",
    "        kwargs.update(\n",
    "            transform=affine,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            crs=to_crs\n",
    "        )\n",
    "        \n",
    "        with rasterio.open(to_out_path, 'w', **kwargs) as dst:\n",
    "            for idx in src.indexes:\n",
    "                rasterio.warp.reproject(\n",
    "                    source=rasterio.band(src, idx), \n",
    "                    destination=rasterio.band(dst, idx)\n",
    "                )\n",
    "        \n",
    "        return to_out_path\n",
    "\n",
    "\n",
    "def reproject_like(template: str, source: str, out_path: str) -> str:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    crs, transform, width, height = fetch_metadata(('crs', 'transform', 'width', 'height'),\n",
    "                                                   template)\n",
    "    \n",
    "    with rasterio.open(source, 'r') as src:\n",
    "        out_kwargs = src.profile.copy()\n",
    "        out_kwargs.update({\n",
    "            'crs': crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(out_path, 'w', **out_kwargs) as dst:\n",
    "            rasterio.warp.reproject(source=rasterio.band(src, list(range(1, src.count + 1))), \n",
    "                                    destination=rasterio.band(dst, list(range(1, src.count + 1))))\n",
    "    \n",
    "    return out_path\n",
    "\n",
    "\n",
    "def merge_from(paths_or_readers: list, **kwargs) -> namedtuple:\n",
    "    \"\"\"\n",
    "    Merges a list of raster files to one single raster dataset.\n",
    "    This method is wrapped around the rasterio.merge.merge method\n",
    "    therefore this method accept keyword arguments as well.\n",
    "    \n",
    "    :param paths_or_readers: list\n",
    "        A list of strings where each list element reference a path to a\n",
    "        raster file on drive.\n",
    "    :param **kwargs:\n",
    "        Please refer to the rasterio documentation for a full list\n",
    "        of possible keyword arguments.\n",
    "    :return: namedtuple(data, affine)\n",
    "        A namedtuple with the attributes data and affine, where the parameter\n",
    "        data contains the merged data of the raster files as a numpy.ndarray \n",
    "        and affine an affine transformation matrix.\n",
    "    \"\"\"\n",
    "    readers = [read_raster(item) for item in paths_or_readers]\n",
    "\n",
    "    dest, affine = rasterio.merge.merge(readers, **kwargs)\n",
    "    \n",
    "    [reader.close() for reader in readers]\n",
    "    Merge = namedtuple('Merge', 'data affine')  \n",
    "    return Merge(dest, affine)\n",
    "\n",
    "\n",
    "def merge_alike(with_template: str, to_merge: list) -> namedtuple:\n",
    "    \"\"\"\n",
    "    Merges the input raster files like a template raster, hence the output\n",
    "    dataset has same bounds and resolution as the template raster. Both datasets\n",
    "    must have the same coordinate reference system.\n",
    "    \n",
    "    :param with_template: str\n",
    "        Path to the template raster file\n",
    "    :param to_merge: list\n",
    "        A list of strings where each list element reference a path to a\n",
    "        raster file on drive.\n",
    "    :return: namedtuple(data, affine)\n",
    "        A namedtuple with the attributes data and affine, where the parameter\n",
    "        data contains the merged data of the raster files as a numpy.ndarray \n",
    "        and affine an affine transformation matrix.\n",
    "    \"\"\"\n",
    "    bounds, res = fetch_metadata(('bounds', 'res'), with_template)\n",
    "    return merge_from(to_merge, bounds=bounds, res=res)\n",
    "\n",
    "\n",
    "def write(data: np.ndarray, to_path: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes a multi-dimensional numpy.ndarray as a raster dataset to file.\n",
    "    This method is wrapped around the rasterio.open method therefore \n",
    "    you can modify the methods behavior  with **kwargs arguements provided\n",
    "    by the rasterio documentation.\n",
    "    \n",
    "    :param data: numpy.ndarray\n",
    "        A multi-dimensional numpy array. If array has three dimensions\n",
    "        each dimension depict a raster band. If array has two dimensions\n",
    "        the resulting raster file contains a sinlge band.\n",
    "    :param to_path: str\n",
    "        Path where the new raster file should be stored\n",
    "    :param **kwargs:\n",
    "        Keyword arguments consumed by the rasterio.open function.\n",
    "        Please refer to the rasterio documentation for a comprehensive\n",
    "        list of possible keyword arguements.\n",
    "    :return: str\n",
    "        Path where the raster file is stored \n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        idx, height, width = data.shape  # z, y, x\n",
    "    elif len(data.shape) == 2:\n",
    "        idx = 1  # z\n",
    "        height, width = data.shape  # y, x\n",
    "        data = np.reshape(data.copy(), (idx, height, width))\n",
    "    else:\n",
    "        raise ValueError('Please, provide a valid dataset')\n",
    "    \n",
    "    dtype = data.dtype\n",
    "    kwargs.update(\n",
    "        count=idx,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        dtype=dtype\n",
    "    )\n",
    "    \n",
    "    with rasterio.open(to_path, 'w', **kwargs) as dst:\n",
    "        for i in range(idx):\n",
    "            dst.write(data[i], i+1)  # rasterio band index start at one, thus we increment by one\n",
    "    \n",
    "    return to_path\n",
    "\n",
    "\n",
    "def int_to_orient(x, y):\n",
    "    \"\"\"\n",
    "    Converts a x- and y-coordinate to an integer north/south,\n",
    "    weste/east string representation.\n",
    "    Example: (x=-179.3457, y=80.2222) -> 80N_179W\n",
    "             \n",
    "    :param x: float\n",
    "        Longitudinal coordinate  \n",
    "    :param y: float\n",
    "        Latitudinal coordinate \n",
    "    :return: str\n",
    "        Lat/Lon coordinates as a integer string with the according\n",
    "        orientation.\n",
    "    \"\"\"\n",
    "    x = round(x)\n",
    "    y = round(y)\n",
    "    \n",
    "    lng, we = (-1 * x, 'W') if x < 0 else (x, 'E')\n",
    "    lat, ns = (-1 * y, 'S') if y < 0 else (y, 'N')\n",
    "    \n",
    "    return '{:02d}{}_{:03d}{}'.format(lat, ns, lng, we)\n",
    "\n",
    "\n",
    "def worker(to_reproject: list, to_crs: dict, to_merge_alike: list, out_path: str, generic_name: str):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    template = None\n",
    "    path = Path(out_path)\n",
    "    \n",
    "    for idx, raster in enumerate(to_reproject):\n",
    "        opath = str(path / 'reproject_{}_{}'.format(idx, generic_name))\n",
    "        \n",
    "        if idx == 0:\n",
    "            template = reproject_from(raster, to_crs, opath)\n",
    "        else:\n",
    "            reproject_like(template, raster, opath)\n",
    "    \n",
    "    kwargs, *_ = fetch_metadata(('profile',), template)\n",
    "    \n",
    "    for idx, rasters in enumerate(to_merge_alike):\n",
    "        opath = str(path / 'merge_{}_{}'.format(idx, generic_name))\n",
    "        \n",
    "        data, transform = merge_alike(template, rasters)\n",
    "        kwargs.update({'transform': transform})\n",
    "        write(data, opath, **kwargs)\n",
    "\n",
    "    \n",
    "def binary_jaccard(arr1, arr2, return_matrix=False):\n",
    "    \"\"\"\n",
    "    Calculates the Jaccard Index (JI) of two equal sized binary arrays or vectors.\n",
    "    If return_matrix is set to true the method provides the JI and the necessary \n",
    "    calculation matrix as a named tuple. Attention, this method does not work in-place!\n",
    "    \n",
    "    :param arr1, arr2: numpy.ndarray, list, tuple\n",
    "        Both array alike objects sized in equal dimensions should contain exclusively \n",
    "        binary data (1,0). \n",
    "    :param return_matrix: boolean\n",
    "        Optional, a boolean value determining the return of the calculation matrix. \n",
    "    :return: float OR (float, namedtuple(m11, m01, m10, m00))\n",
    "        Defaultly, the method returns only the JI if, return_matrix is set to true the \n",
    "        method returns the JI and the computation matrix.\n",
    "        The Matrix contains the following attributes:\n",
    "        m11 = total number of attributes where arr1 == 1 and arr2 == 1\n",
    "        m10 = total number of attributes where arr1 == 1 and arr2 == 0\n",
    "        m01 = total number of attributes where arr1 == 0 and arr2 == 1\n",
    "        m00 = not required, set to 0\n",
    "    \"\"\"\n",
    "    A, B = np.array(arr1, dtype=np.int8), np.array(arr2, dtype=np.int8)\n",
    "    \n",
    "    if np.sum(np.logical_or(A<0,A>1)) != 0 or np.sum(np.logical_or(B<0,B>1)) != 0:\n",
    "        raise ValueError('Attributes should contain only binary values')\n",
    "  \n",
    "    C = A + B\n",
    "    a = (B - C) + B  # a = (A - C) + A, m10 = a == 1\n",
    "    b = (A - C) + A  # b = (B - C) + B, m01 = b == 1\n",
    "\n",
    "    # Total number of attributes where A == 1 and B == 1\n",
    "    m11 = np.sum(C==2)\n",
    "    # Total number of attributes where A == 1 and B == 0\n",
    "    m10 = np.sum(a==-1)\n",
    "    # Total number of attributes where A == 0 and B == 1\n",
    "    m01 = np.sum(b==-1)\n",
    "    \n",
    "    jaccard = m11 / (m10 + m01 + m11)\n",
    "    \n",
    "    if return_matrix:\n",
    "        Matrix = namedtuple('Matrix', 'm11 m10 m01 m00')\n",
    "        return jaccard, Matrix(m11, m10, m01, 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def simple_matching_coefficient(arr1, arr2, return_matrix=False):\n",
    "    \"\"\"\n",
    "    Calculates the Simple Matching Coefficient (SMC) of two equal sized arrays or vectors.\n",
    "    If return_matrix is set to true the method provides the SMC and the necessary calculation \n",
    "    matrix as a named tuple. Attention, this method does not work in-place!\n",
    "    \n",
    "    :param arr1, arr2: numpy.ndarray, list, tuple\n",
    "        Both array alike objects sized in equal dimensions should contain exclusively \n",
    "        binary data (1,0).\n",
    "    :param return_matrix: boolean\n",
    "        Optional, a boolean value determining the return of the calculation matrix.\n",
    "    :return: float OR (float, namedtuple(m11, m01, m10, m00))\n",
    "        Defaultly, the method returns only the SMC, if return_matrix is\n",
    "        set to true the method returns the SMC and the computation matrix.\n",
    "        The Matrix contains the following attributes:\n",
    "        m11 = total number of attributes where arr1 == 1 and arr2 == 1\n",
    "        m10 = total number of attributes where arr1 == 1 and arr2 == 0\n",
    "        m01 = total number of attributes where arr1 == 0 and arr2 == 1\n",
    "        m00 = total number of attributes where arr1 == 0 and arr2 == 0\n",
    "    \"\"\"\n",
    "    _, matrix = binary_jaccard(arr1, arr2, True)\n",
    "    A = np.array(arr1, dtype=np.int8)\n",
    "    \n",
    "    # Total number of attributes where A == 0 and B == 0\n",
    "    m00 = A.size - sum(matrix)\n",
    "    \n",
    "    smc = (matrix.m11 + m00) / A.size\n",
    "\n",
    "    if return_matrix:\n",
    "        matrix = matrix._replace(m00=m00)\n",
    "        return smc, matrix\n",
    "    return smc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFC mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cover</th>\n",
       "      <th>gain</th>\n",
       "      <th>loss</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_000E.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_000E.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_000E.tif</td>\n",
       "      <td>POLYGON ((-0.0001388888888982365 0.00013888888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_010E.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_010E.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_010E.tif</td>\n",
       "      <td>POLYGON ((9.999861111111102 0.0001388888888840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_010W.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_010W.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_010W.tif</td>\n",
       "      <td>POLYGON ((-10.0001388888889 0.0001388888888840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_020E.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_020E.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_020E.tif</td>\n",
       "      <td>POLYGON ((19.9998611111111 0.00013888888888402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hansen_GFC2013_treecover2000_00N_020W.tif</td>\n",
       "      <td>Hansen_GFC2013_gain_00N_020W.tif</td>\n",
       "      <td>Hansen_GFC2013_lossyear_00N_020W.tif</td>\n",
       "      <td>POLYGON ((-20.0001388888889 0.0001388888888840...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       cover  \\\n",
       "0  Hansen_GFC2013_treecover2000_00N_000E.tif   \n",
       "1  Hansen_GFC2013_treecover2000_00N_010E.tif   \n",
       "2  Hansen_GFC2013_treecover2000_00N_010W.tif   \n",
       "3  Hansen_GFC2013_treecover2000_00N_020E.tif   \n",
       "4  Hansen_GFC2013_treecover2000_00N_020W.tif   \n",
       "\n",
       "                               gain                                  loss  \\\n",
       "0  Hansen_GFC2013_gain_00N_000E.tif  Hansen_GFC2013_lossyear_00N_000E.tif   \n",
       "1  Hansen_GFC2013_gain_00N_010E.tif  Hansen_GFC2013_lossyear_00N_010E.tif   \n",
       "2  Hansen_GFC2013_gain_00N_010W.tif  Hansen_GFC2013_lossyear_00N_010W.tif   \n",
       "3  Hansen_GFC2013_gain_00N_020E.tif  Hansen_GFC2013_lossyear_00N_020E.tif   \n",
       "4  Hansen_GFC2013_gain_00N_020W.tif  Hansen_GFC2013_lossyear_00N_020W.tif   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-0.0001388888888982365 0.00013888888...  \n",
       "1  POLYGON ((9.999861111111102 0.0001388888888840...  \n",
       "2  POLYGON ((-10.0001388888889 0.0001388888888840...  \n",
       "3  POLYGON ((19.9998611111111 0.00013888888888402...  \n",
       "4  POLYGON ((-20.0001388888889 0.0001388888888840...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfc = sorted(DIRS.gfc.glob('*.tif'))\n",
    "\n",
    "data_len = int(len(gfc)/3)\n",
    "\n",
    "kwargs = {\n",
    "    'gain': [i.name for i in gfc[:data_len]],\n",
    "    'loss': [i.name for i in gfc[data_len:2*data_len]],\n",
    "    'cover': [i.name for i in gfc[2*data_len:]],\n",
    "}\n",
    "\n",
    "gfc_mask = tile_index(gfc[:data_len], WGS84, **kwargs)\n",
    "gfc_mask.to_file(str(DIRS.masks / 'gfc_mask.shp'))\n",
    "gfc_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GL30 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gl30_00</th>\n",
       "      <th>gl30_10</th>\n",
       "      <th>key</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02_15_2000lc030.tif</td>\n",
       "      <td>n02_15_2010lc030.tif</td>\n",
       "      <td>n02_15</td>\n",
       "      <td>POLYGON ((-174.0053601744084 20.00401663536249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n03_05_2000lc030.tif</td>\n",
       "      <td>n03_05_2010lc030.tif</td>\n",
       "      <td>n03_05</td>\n",
       "      <td>POLYGON ((-168.0054833302891 10.00519024901941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n03_20_2000lc030.tif</td>\n",
       "      <td>n03_20_2010lc030.tif</td>\n",
       "      <td>n03_20</td>\n",
       "      <td>POLYGON ((-168.0051433812486 25.00312959291788...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n04_00_2000lc030.tif</td>\n",
       "      <td>n04_00_2010lc030.tif</td>\n",
       "      <td>n04_00</td>\n",
       "      <td>POLYGON ((-162.0055192236557 5.005478418984219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n04_05_2000lc030.tif</td>\n",
       "      <td>n04_05_2010lc030.tif</td>\n",
       "      <td>n04_05</td>\n",
       "      <td>POLYGON ((-162.0054833302891 10.0051902490194,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gl30_00               gl30_10     key  \\\n",
       "0  n02_15_2000lc030.tif  n02_15_2010lc030.tif  n02_15   \n",
       "1  n03_05_2000lc030.tif  n03_05_2010lc030.tif  n03_05   \n",
       "2  n03_20_2000lc030.tif  n03_20_2010lc030.tif  n03_20   \n",
       "3  n04_00_2000lc030.tif  n04_00_2010lc030.tif  n04_00   \n",
       "4  n04_05_2000lc030.tif  n04_05_2010lc030.tif  n04_05   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-174.0053601744084 20.00401663536249...  \n",
       "1  POLYGON ((-168.0054833302891 10.00519024901941...  \n",
       "2  POLYGON ((-168.0051433812486 25.00312959291788...  \n",
       "3  POLYGON ((-162.0055192236557 5.005478418984219...  \n",
       "4  POLYGON ((-162.0054833302891 10.0051902490194,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gl30 = sorted(DIRS.gl30.glob('*.tif'), key=lambda key: (key.name[7:11], key.name[0:6]))\n",
    "\n",
    "exclude = 'n01_00 s01_00 s01_10 s01_15 s01_20 s60_00 s60_05 s60_10 s60_15 n53_00'.split()\n",
    "gl30 = [item for item in gl30 if item.name[0:6] not in exclude]\n",
    "data_len = int(len(gl30)/2)\n",
    "\n",
    "kwargs = {\n",
    "    'gl30_00': [i.name for i in gl30[:data_len]],\n",
    "    'gl30_10': [i.name for i in gl30[data_len:]],\n",
    "    'key': [i.name[0:6] for i in gl30[:data_len]]\n",
    "}\n",
    "\n",
    "gl30_mask = tile_index(gl30[data_len:], WGS84, **kwargs)\n",
    "gl30_mask.to_file(str(DIRS.masks / 'gl30_mask.shp'))\n",
    "gl30_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biomass mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biomass</th>\n",
       "      <th>confidence</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10N_090W_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_10N_090W.tif</td>\n",
       "      <td>POLYGON ((-90.0001388885744 0.0001388894243932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10N_050E_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_10N_050E.tif</td>\n",
       "      <td>POLYGON ((49.9998611109019 7.999861110840482, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10S_170E_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_10S_170E.tif</td>\n",
       "      <td>POLYGON ((169.9998611109663 -12.00013888921919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20N_100W_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_20N_100W.tif</td>\n",
       "      <td>POLYGON ((-100.0001388891786 13.00013888876461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20S_020E_merge.tif</td>\n",
       "      <td>merged_per_tropical_asia_20S_020E.tif</td>\n",
       "      <td>POLYGON ((19.99986111088579 -29.99986111075941...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              biomass                             confidence  \\\n",
       "0  10N_090W_merge.tif  merged_per_tropical_asia_10N_090W.tif   \n",
       "1  10N_050E_merge.tif  merged_per_tropical_asia_10N_050E.tif   \n",
       "2  10S_170E_merge.tif  merged_per_tropical_asia_10S_170E.tif   \n",
       "3  20N_100W_merge.tif  merged_per_tropical_asia_20N_100W.tif   \n",
       "4  20S_020E_merge.tif  merged_per_tropical_asia_20S_020E.tif   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-90.0001388885744 0.0001388894243932...  \n",
       "1  POLYGON ((49.9998611109019 7.999861110840482, ...  \n",
       "2  POLYGON ((169.9998611109663 -12.00013888921919...  \n",
       "3  POLYGON ((-100.0001388891786 13.00013888876461...  \n",
       "4  POLYGON ((19.99986111088579 -29.99986111075941...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biomass = gpd.read_file(str(DIRS.masks / 'biomass.geojson'))\n",
    "biomass_mask = biomass.drop(biomass.columns[[0, 1, 4, 5]], axis=1)\n",
    "biomass_mask.rename(columns={'download': 'biomass'}, inplace=True)\n",
    "\n",
    "for idx, row in biomass_mask.iterrows():\n",
    "    biomass = row.biomass.split('/')[-1]\n",
    "    confidence = row.confidence.split('/')[-1]\n",
    "    \n",
    "    biomass_mask.at[idx, 'biomass'] = biomass\n",
    "    biomass_mask.at[idx, 'confidence'] = confidence\n",
    "\n",
    "biomass_mask.to_file(str(DIRS.masks / 'biomass_mask.shp'))\n",
    "biomass_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster alignment\n",
    "- include soil layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7eb0dc71be01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTHREADLIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-7eb0dc71be01>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTHREADLIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gl30_mask = gpd.read_file(str(DIRS.masks / 'gl30_mask.shp'))\n",
    "gfc_mask = gpd.read_file(str(DIRS.masks / 'gfc_mask.shp'))\n",
    "biomass_mask = gpd.read_file(str(DIRS.masks / 'biomass_mask.shp'))\n",
    "gsoc_mask = None\n",
    "\n",
    "intersect = gpd.overlay(gfc_mask, gl30_mask, how='intersection')\n",
    "intersect = gpd.overlay(intersect, biomass_mask, how='intersection')\n",
    "\n",
    "threads = []\n",
    "for key, values in intersect.groupby(by='key', sort=False):\n",
    "    if len(threads) == THREADLIMIT:\n",
    "        [thread.join() for thread in threads]\n",
    "        threads = []\n",
    "    \n",
    "    to_reproject = [\n",
    "        str(DIRS.gl30 / name)\n",
    "        for name in list(*zip(set(values.gl30_10), set(values.gl30_00)))\n",
    "    ]\n",
    "    to_merge = [\n",
    "        [str(DIRS.gfc / name) for name in set(values.gain)],\n",
    "        [str(DIRS.gfc / name) for name in set(values.cover)],\n",
    "        [str(DIRS.gfc / name) for name in set(values.loss)],\n",
    "        [str(DIRS.biomass / name) for name in set(values.biomass)]\n",
    "    ]\n",
    "    generic_name = 'test_{}.tif'.format(key)\n",
    "    \n",
    "    thread = threading.Thread(target=worker,\n",
    "                              args=(to_reproject, WGS84, to_merge, str(DIRS.proc), generic_name))\n",
    "    thread.start()\n",
    "    threads.append(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Croping\n",
    "- goal crop to a feasible extent (get rid of nodata values)\n",
    "- create final mask with all layers attributes:\n",
    "    - gain \n",
    "    - cover \n",
    "    - loss\n",
    "    - gl30_00\n",
    "    - gl30_10 \n",
    "    - soil\n",
    "    - biomass\n",
    "    - biomass error\n",
    "    - key = top, left coordinate of a layer set\n",
    "    - region = continental orientation (america, afric or asia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial harmonization\n",
    "Workflow\n",
    "- consider to use additional classes from gl30 wetlands or tundra\n",
    "- initial\n",
    "    - select forest (class value 20) from dataset gl30 - 2000\n",
    "    - recode values to binary format 20 = 1, 0 = 0\n",
    "    - select forest (class value 0 - 100) from hansen tree cover 2000\n",
    "    - recode values to binary format 1 - 100 = 1, 0 = 0\n",
    "    - calculate Jaccard Index with chen and hansen\n",
    "- looping\n",
    "    - select forest (0 + 10) - 100 from hansen tree cover 2000\n",
    "    - recode values to binary format (0 + 10) - 100 = 1, 0 = 0\n",
    "    - calculate Jaccard Index with chen and hansen\n",
    "    - do till 30 or Jaccard Index is max\n",
    "Potential Images\n",
    "- world agreement map with different \n",
    "    - compare chen and hansen treccover in one image\n",
    "    - sum of both dataset\n",
    "    - 2 = agreement, 1 = disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of irelevant values is most convenient with\n",
    "arr[np.isin(arr, [1,3,4])] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "lit.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
