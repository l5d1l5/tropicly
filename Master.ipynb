{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"cffea22b-efc0-407c-86b3-7c13fd87778b\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"cffea22b-efc0-407c-86b3-7c13fd87778b\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"cffea22b-efc0-407c-86b3-7c13fd87778b\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'cffea22b-efc0-407c-86b3-7c13fd87778b' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"cffea22b-efc0-407c-86b3-7c13fd87778b\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"cffea22b-efc0-407c-86b3-7c13fd87778b\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"cffea22b-efc0-407c-86b3-7c13fd87778b\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'cffea22b-efc0-407c-86b3-7c13fd87778b' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"cffea22b-efc0-407c-86b3-7c13fd87778b\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import queue\n",
    "import zipfile\n",
    "import logging\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio  # delete\n",
    "import geopandas as gpd\n",
    "\n",
    "from src.utils import *\n",
    "from pathlib import Path\n",
    "from affine import Affine  # delete\n",
    "from collections import Counter  # delete\n",
    "from rasterio import features  # delete\n",
    "from bokeh.transform import jitter\n",
    "from bokeh.layouts import gridplot\n",
    "from collections import defaultdict\n",
    "from shapely.geometry import Polygon  # delete\n",
    "from IPython.display import clear_output\n",
    "from bokeh.models import HoverTool, FactorRange\n",
    "from bokeh.plotting import output_notebook, show, figure, ColumnDataSource\n",
    "\n",
    "from src.utils import assignment_worker\n",
    "\n",
    "directories = \"\"\"\n",
    "data\n",
    "data.log\n",
    "data.tmp\n",
    "data.ana\n",
    "data.proc\n",
    "data.core\n",
    "data.core.ifl\n",
    "data.core.gfc\n",
    "data.core.soil\n",
    "data.core.gl30\n",
    "data.core.esvd\n",
    "data.core.biomass\n",
    "data.auxiliary\n",
    "data.auxiliary.masks\n",
    "\"\"\"\n",
    "\n",
    "for item in directories.split():\n",
    "    path = os.sep.join(item.split('.'))\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "# Convenient access to data directory, is a namedtuple with folder names as attributes\n",
    "DIRS = get_data_dir(str(Path('data').resolve()))\n",
    "    \n",
    "# init Logging\n",
    "formater = logging.Formatter('%(asctime)s %(levelname)s: %(message)s', '%d/%m/%y %H:%M:%S')\n",
    "handler = logging.FileHandler(str(DIRS.log / 'utils.log'), 'a+')\n",
    "handler.setLevel(logging.DEBUG)\n",
    "handler.setFormatter(formater)\n",
    "\n",
    "# LOGGER.setLevel(logging.DEBUG)\n",
    "# LOGGER.addHandler(handler)\n",
    "\n",
    "# Many functions of the processing pipeline are multi-threaded this attribute controls\n",
    "# max number of threads\n",
    "THREADLIMIT = 12\n",
    "\n",
    "SPOOF_AGENT = {'headers': {'User-Agent': \"Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11\"}}\n",
    "\n",
    "WGS84 = {'init': 'epsg:4326'}\n",
    "\n",
    "# force bokeh plot output to jupyter notebook\n",
    "output_notebook()\n",
    "\n",
    "def callback(msg, ratio):\n",
    "    clear_output()\n",
    "    print(msg.format(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Forest Change\n",
    "[**Global Forest Change 2000-2012 Version 1.0**](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.0.html) (GFC) is the first high resolution dataset that provides a comprehensive view on the annual global forest cover change between 2000 and 2012 \\cite{Hansen2013, Li2017}. The initial GFC dataset released by Hansen et al. is extended by recent releases which encompass the annual forest cover changes between [2000-2013 (Version 1.1)](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.1.html), [2000-2014 (Version 1.2)](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.2.html), [2000-2015 (Version 1.3)](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.3.html) and [2000-2016 (Version 1.4)](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.4.html) respectively. All versions of this dataset has in common, that they are derived from growing season imagery captured by the remote sensing satellite Landsat 7 Enhanced Thematic Mapper Plus (ETM+) at a spatial resolution of 30 meters per pixel \\cite{Hansen2013a}. On the satellite imagery a time-series spectral metrics analysis is applied to gather the global forest extent at 2000 as well as the annual forest loss and gain. Hence, GFC comprises three independent data layers  tree cover, annually forest loss and  forest gain divided into 10x10 degree tiles by the geodetic coordinate system *World Geodetic System 1984* (EPSG:4326). Furthermore, across the provided layers the pixel data is coded in unsigned 8 bit integers. Hansen et al. defined trees as all vegetation taller than 5 meters for their study. Forest loss is defined as a stand displacement disturbance leading from a forest state to a non forest-state. To compute this losses \n",
    "\n",
    "[Global Forest Watch](http://www.globalforestwatch.org/) interactive map\n",
    "\n",
    "- Flow general what is gfc then detailed info monitoring method, details of the different layers, how certain is the info\n",
    "- trees defined as all vegetation higher than 5 meters Hansen2013, Hansen2013a\n",
    "- forest loss defined as a stand displacement disturbance (> x% crown cover to 0% crown cover)  Hansen2013, Hansen2013a\n",
    "- monitored by a reference percent tree cover stratum Hansen2013, Hansen2013a\n",
    "- forest degeneration for example selective removals btw. all impacts on forest which are not lead to a non forest state are not considered Hansen2013a\n",
    "- term forest refer to tree cover Hansen2013a\n",
    "- gain is the inverse of loss e.g. the change of a non forest state to forest (crown cover densities >50%)\n",
    "- Forest loss detection is less uncertain then gain detection (loss is more reliable) Li2017\n",
    "- Gain is a more gradual and ecological complex process, signal is more difficult to detect Li2017\n",
    "- Li2017 compares 4 different forest cover change products on their performance to estimate loss and gain patterns in china\n",
    "- at the end show a example picture of the data\n",
    "\n",
    "\n",
    "\\cite{Hansen2013}\n",
    "\\cite{Hansen2013a}\n",
    "\\cite{Tropek2014}\n",
    "\\cite{Bellot2014}\n",
    "\\cite{Li2017}\n",
    "\\cite{Li2017a}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hansen preview](img/hansen_preview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data source URL\n",
    "head = 'http://commondatastorage.googleapis.com/earthenginepartners-hansen/GFC2013/'\n",
    "# files to download from source url\n",
    "tails = 'treecover2000.txt gain.txt lossyear.txt'.split()\n",
    "\n",
    "data_urls = []\n",
    "for tail in tails:\n",
    "    content = download(head + tail)\n",
    "    data_urls += content.decode('utf-8').splitlines()\n",
    "\n",
    "threads = []\n",
    "for url in data_urls:\n",
    "    lat_lon = re.search(r'(\\d{2}\\w_\\d{3}\\w)(?=\\.tif)', url).groups()[0]\n",
    "    lat = orientation_to_int(lat_lon.split('_')[0])\n",
    "    if -20 <= lat <= 30:\n",
    "        path = str(DIRS.gfc / url.split('/')[-1])\n",
    "        threads.append(threading.Thread(target=download_worker, args=(url, path)))\n",
    "\n",
    "execute_threads(threads, THREADLIMIT, 'Downloaded {} of 100 %', callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GlobalLand30\n",
    "[GlobLand30](http://www.globallandcover.com/GLC30Download/index.aspx) (GL30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Chen preview](img/chen_preview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aboveground live woody biomass density\n",
    "[Aboveground Live Woody Biomass Density](http://data.globalforestwatch.org/datasets/8f93a6f94a414f9588ce4657a39c59ff_1) (LWBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://data.globalforestwatch.org/datasets/8f93a6f94a414f9588ce4657a39c59ff_1.geojson'\n",
    "path = str(DIRS.masks / 'biomass.geojson')\n",
    "\n",
    "content = download(url)\n",
    "write_binary(content, path)\n",
    "\n",
    "biomass_mask = gpd.read_file(path)\n",
    "to_download = list(biomass_mask.download) + list(biomass_mask.confidence) \n",
    "\n",
    "threads = []\n",
    "for url in to_download:\n",
    "    path = str(DIRS.biomass / url.split('/')[-1])\n",
    "    threads.append(\n",
    "        threading.Thread(target=download_worker, args=(url, path), kwargs=SPOOF_AGENT)\n",
    "    )\n",
    "\n",
    "execute_threads(threads, THREADLIMIT, msg='Donwloaded {} % of 100 %', callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global soil organic carbon map\n",
    "[The Global Soil Organic Carbon Map](http://www.fao.org/world-soil-day/global-soil-organic-carbon-map/en/) (GSOCmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download broken fix it please\n",
    "url = 'https://unfao-my.sharepoint.com/personal/guillermo_olmedo_fao_org/_layouts/15/guestaccess.aspx?docid=059b0b724d08a42e4931c35cff99a15c1&authkey=AcRgiPkRQvm_kuJb-K0-e2o&e=e70096969c4e4ce084d2ee1d1ca8bc44'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.soil / 'GSOCmap.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecosystem service valuation database\n",
    "[Ecosystem Service Valuation Database](https://www.es-partnership.org/services/data-knowledge-sharing/ecosystem-service-valuation-database/) (ESVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.es-partnership.org/wp-content/uploads/2016/06/ESVD-TEEB-database.xls'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.esvd / url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intact Forest Landscapes\n",
    "[Intact Forest Landscapes](http://intactforests.org/index.html) (IFL2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://intactforests.org/shp/IFL_2000.zip'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.ifl / url.split('/')[-1]))\n",
    "\n",
    "zipfile.ZipFile(str(DIRS.ifl / url.split('/')[-1])).extractall(str(DIRS.ifl))\n",
    "os.remove(str(DIRS.ifl / url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Natural Earth Data](http://www.naturalearthdata.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_populated_places.zip'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.masks / url.split('/')[-1]))\n",
    "\n",
    "zipfile.ZipFile(str(DIRS.masks / url.split('/')[-1])).extractall(str(DIRS.masks))\n",
    "os.remove(str(DIRS.masks / url.split('/')[-1]))\n",
    "\n",
    "url = 'http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries.zip'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.masks / url.split('/')[-1]))\n",
    "\n",
    "zipfile.ZipFile(str(DIRS.masks / url.split('/')[-1])).extractall(str(DIRS.masks))\n",
    "os.remove(str(DIRS.masks / url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GFC mask\n",
    "gfc = sorted(DIRS.gfc.glob('*.tif'))\n",
    "\n",
    "data_len = int(len(gfc)/3)\n",
    "\n",
    "kwargs = {\n",
    "    'gain': [i.name for i in gfc[:data_len]],\n",
    "    'loss': [i.name for i in gfc[data_len:2*data_len]],\n",
    "    'cover': [i.name for i in gfc[2*data_len:]],\n",
    "}\n",
    "\n",
    "gfc_mask = tile_index(gfc[:data_len], WGS84, **kwargs)\n",
    "gfc_mask.to_file(str(DIRS.masks / 'gfc_mask.shp'))\n",
    "gfc_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gl30_00</th>\n",
       "      <th>gl30_10</th>\n",
       "      <th>key</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02_15_2000lc030.tif</td>\n",
       "      <td>n02_15_2010lc030.tif</td>\n",
       "      <td>n02_15</td>\n",
       "      <td>POLYGON ((-174.0053601744084 20.00401663536249...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n03_05_2000lc030.tif</td>\n",
       "      <td>n03_05_2010lc030.tif</td>\n",
       "      <td>n03_05</td>\n",
       "      <td>POLYGON ((-168.0054833302891 10.00519024901941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n03_20_2000lc030.tif</td>\n",
       "      <td>n03_20_2010lc030.tif</td>\n",
       "      <td>n03_20</td>\n",
       "      <td>POLYGON ((-168.0051433812486 25.00312959291788...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n04_00_2000lc030.tif</td>\n",
       "      <td>n04_00_2010lc030.tif</td>\n",
       "      <td>n04_00</td>\n",
       "      <td>POLYGON ((-162.0055192236557 5.005478418984219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n04_05_2000lc030.tif</td>\n",
       "      <td>n04_05_2010lc030.tif</td>\n",
       "      <td>n04_05</td>\n",
       "      <td>POLYGON ((-162.0054833302891 10.0051902490194,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gl30_00               gl30_10     key  \\\n",
       "0  n02_15_2000lc030.tif  n02_15_2010lc030.tif  n02_15   \n",
       "1  n03_05_2000lc030.tif  n03_05_2010lc030.tif  n03_05   \n",
       "2  n03_20_2000lc030.tif  n03_20_2010lc030.tif  n03_20   \n",
       "3  n04_00_2000lc030.tif  n04_00_2010lc030.tif  n04_00   \n",
       "4  n04_05_2000lc030.tif  n04_05_2010lc030.tif  n04_05   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-174.0053601744084 20.00401663536249...  \n",
       "1  POLYGON ((-168.0054833302891 10.00519024901941...  \n",
       "2  POLYGON ((-168.0051433812486 25.00312959291788...  \n",
       "3  POLYGON ((-162.0055192236557 5.005478418984219...  \n",
       "4  POLYGON ((-162.0054833302891 10.0051902490194,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GL30 mask\n",
    "gl30 = sorted(DIRS.gl30.glob('*.tif'), key=lambda key: (key.name[7:11], key.name[0:6]))\n",
    "\n",
    "exclude = 'n01_00 s01_00 s01_10 s01_15 s01_20 s60_00 s60_05 s60_10 s60_15 n53_00'.split()\n",
    "gl30 = [item for item in gl30 if item.name[0:6] not in exclude]\n",
    "data_len = int(len(gl30)/2)\n",
    "\n",
    "kwargs = {\n",
    "    'gl30_00': [i.name for i in gl30[:data_len]],\n",
    "    'gl30_10': [i.name for i in gl30[data_len:]],\n",
    "    'key': [i.name[0:6] for i in gl30[:data_len]]\n",
    "}\n",
    "\n",
    "gl30_mask = tile_index(gl30[data_len:], WGS84, **kwargs)\n",
    "gl30_mask.to_file(str(DIRS.masks / 'gl30_mask.shp'))\n",
    "gl30_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Biomass mask\n",
    "biomass = gpd.read_file(str(DIRS.masks / 'biomass.geojson'))\n",
    "biomass_mask = biomass.drop(biomass.columns[[0, 1, 4, 5]], axis=1)\n",
    "biomass_mask.rename(columns={'download': 'biomass'}, inplace=True)\n",
    "\n",
    "for idx, row in biomass_mask.iterrows():\n",
    "    biomass = row.biomass.split('/')[-1]\n",
    "    confidence = row.confidence.split('/')[-1]\n",
    "    \n",
    "    biomass_mask.at[idx, 'biomass'] = biomass\n",
    "    biomass_mask.at[idx, 'confidence'] = confidence\n",
    "\n",
    "biomass_mask.to_file(str(DIRS.masks / 'biomass_mask.shp'))\n",
    "biomass_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raster alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gl30_mask = gpd.read_file(str(DIRS.masks / 'gl30_mask.shp'))\n",
    "gfc_mask = gpd.read_file(str(DIRS.masks / 'gfc_mask.shp'))\n",
    "biomass_mask = gpd.read_file(str(DIRS.masks / 'biomass_mask.shp'))\n",
    "\n",
    "intersect = gpd.overlay(gfc_mask, gl30_mask, how='intersection')\n",
    "intersect = gpd.overlay(intersect, biomass_mask, how='intersection')\n",
    "\n",
    "threads = []\n",
    "for key, values in intersect.groupby(by='key', sort=False):\n",
    "    to_reproject = [\n",
    "        str(DIRS.gl30 / name)\n",
    "        for name in list(*zip(set(values.gl30_10), set(values.gl30_00)))\n",
    "    ]\n",
    "    to_reproject.append(str(DIRS.soil / 'GSOCmapV1.1.tif'))\n",
    "    to_merge = [\n",
    "        [str(DIRS.gfc / name) for name in set(values.cover)],\n",
    "        [str(DIRS.gfc / name) for name in set(values.loss)],\n",
    "        [str(DIRS.gfc / name) for name in set(values.gain)],\n",
    "        [str(DIRS.biomass / name) for name in set(values.biomass)],\n",
    "        [str(DIRS.biomass / name) for name in set(values.confidence)],\n",
    "    ]\n",
    "    generic_name = '{}.tif'.format(key)\n",
    "    \n",
    "    threads.append(\n",
    "        threading.Thread(target=alignment_worker,\n",
    "                         args=(to_reproject, WGS84, to_merge, str(DIRS.proc), generic_name))\n",
    "    )\n",
    "    \n",
    "execute_threads(threads, THREADLIMIT, msg='Aligned {} % of 100 %', callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping and masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = defaultdict(list)\n",
    "regex = re.compile(r'.*(?P<key>(?:n|s)\\d{2}_\\d{2}).*', re.I)\n",
    "\n",
    "for path in DIRS.proc.glob('*.tif'):\n",
    "    match = regex.match(str(path))\n",
    "    files[match.group('key')].append(path)\n",
    "    files[match.group('key')] = sorted(files[match.group('key')])\n",
    "\n",
    "threads = []\n",
    "features = []\n",
    "polygons = []\n",
    "for key, values in files.items():   \n",
    "    bounds, profile = fetch_metadata(values[0], 'bounds', 'profile')\n",
    "    bounds = round_bounds(bounds)\n",
    "\n",
    "    threads.append(\n",
    "        threading.Thread(target=clip_worker, args=(values, bounds, profile, str(DIRS.proc),))\n",
    "    )\n",
    "    \n",
    "    key = int_to_orient(bounds.left, bounds.top)\n",
    "    feature = dict([dispatch_name('{0[0]}_{0[1]}'.format(item.name.split('_')), key, idx)\n",
    "                    for idx, item in enumerate(values)])\n",
    "    feature['key'] = key\n",
    "    features.append(feature)\n",
    "    polygons.append(polygon_from(bounds))\n",
    "    \n",
    "execute_threads(threads, THREADLIMIT, msg='Cropped {} % of 100 %', callback=callback)\n",
    "\n",
    "geometry = gpd.GeoSeries(polygons)\n",
    "df = pd.DataFrame(features)\n",
    "layer = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "layer.crs = WGS84\n",
    "\n",
    "layer.to_file(str(DIRS.masks / 'final_mask.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = gpd.read_file(str(DIRS.masks / 'ne_10m_admin_0_countries.shp'))\n",
    "tiles = gpd.read_file(str(DIRS.masks / 'final_mask.shp'))\n",
    "tiles.crs = WGS84\n",
    "\n",
    "aoi = countries.cx[:,-23:23]\n",
    "aoi = aoi[['REGION_UN', 'geometry']]\n",
    "continents = aoi.dissolve(by='REGION_UN')\n",
    "\n",
    "layer = gpd.sjoin(tiles, continents, how='left', op='intersects')\n",
    "layer.to_file(str(DIRS.masks / 'final_region_mask.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = gpd.read_file(str(DIRS.masks / 'final_region_mask.shp'))\n",
    "q = queue.Queue()\n",
    "\n",
    "threads = [\n",
    "    threading.Thread(target=harmonization_worker,\n",
    "                     args=(DIRS.proc/val.gl30_00, DIRS.proc/val.cover, q, val.key, val.index_righ))\n",
    "    for idx, val in mask.iterrows()\n",
    "]\n",
    "\n",
    "execute_threads(threads, THREADLIMIT, msg='Harmonization {} % of 100 %', callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = []\n",
    "while not q.empty():\n",
    "    vals.append(q.get())\n",
    "\n",
    "df = pd.DataFrame(vals)\n",
    "df.columns = ['tile', 'region', 'jc0', 'smc0', 'jc10', 'smc10', 'jc20', 'smc20', 'jc30', 'smc30']\n",
    "df.to_csv(DIRS.ana/'class_harmon_wet.csv', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deforestation drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = drivers_gain > 0\n",
    "\n",
    "# RASTER TO VECTOR\n",
    "features = [\n",
    "    (attr, Polygon(geo['coordinates'][0]))\n",
    "    for geo, attr in rio.features.shapes(drivers_gain, mask, transform=transform)\n",
    "]\n",
    "attrs, polygons = list(zip(*features))\n",
    "\n",
    "geometry = gpd.GeoSeries(polygons)\n",
    "df = pd.DataFrame(np.array(attrs, dtype=np.uint8), columns=['label'])\n",
    "\n",
    "layer = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "layer.crs = {'init': 'epsg:32633'}\n",
    "\n",
    "layer.to_file(str(DIRS.tmp/'all.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(25, 6)]\n",
      "[(25, 3)]\n",
      "[(25, 2)]\n",
      "[(25, 5)]\n"
     ]
    }
   ],
   "source": [
    "unclass = layer[layer['label'] == 20].copy()\n",
    "unclass['geometry'] = unclass.centroid\n",
    "unclass['geometry'] = unclass.buffer(50)\n",
    "\n",
    "unclass.label = unclass.index\n",
    "\n",
    "intersection = gpd.overlay(layer, unclass, how='intersection')\n",
    "\n",
    "for group, df in intersection.groupby(by='label_2', sort=False):\n",
    "    c = Counter(df.label)\n",
    "    print(c.most_common(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = pd.read_csv(str(DIRS.ana / 'class_harmon_wet.csv'))\n",
    "\n",
    "# initial data clean up\n",
    "src.rename(columns=lambda x: x.upper() if x[:2] == 'jc' else x, inplace=True)\n",
    "src.drop('smc0 smc10 smc20 smc30'.split(), axis=1, inplace=True)\n",
    "src.drop(src.columns[0], axis=1, inplace=True)\n",
    "src.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "# scatterplot data prep\n",
    "melted = src.melt(id_vars='tile region'.split(), var_name='jc_class', value_name='score')\n",
    "melted['colors'] = '#ffffff'\n",
    "melted.loc[melted['jc_class'] == 'JC0', 'colors'] = '#e66101'\n",
    "melted.loc[melted['jc_class'] == 'JC10', 'colors'] = '#fdb863'\n",
    "melted.loc[melted['jc_class'] == 'JC20', 'colors'] = '#b2abd2'\n",
    "melted.loc[melted['jc_class'] == 'JC30', 'colors'] = '#5e3c99'\n",
    "melted.sort_values(by=['region', 'jc_class'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# boxplot data prep\n",
    "frames = []\n",
    "for key, df in src.groupby('region'):\n",
    "    boxplot = df.quantile(q=(0.25, 0.5, 0.75)).T\n",
    "    boxplot.columns = ['q1', 'q2', 'q3']\n",
    "    boxplot['iqr'] = boxplot.q3 - boxplot.q1\n",
    "    boxplot['tukey_lower_whisker'] = boxplot.q1 - 1.5 * boxplot.iqr\n",
    "    boxplot['tukey_upper_whisker'] = boxplot.q3 + 1.5 * boxplot.iqr\n",
    "    boxplot['q_lower_whisker'] = df.quantile(q=0.025)\n",
    "    boxplot['q_upper_whisker'] = df.quantile(q=0.975)\n",
    "    boxplot['min_whisker'] = df.min()\n",
    "    boxplot['max_whisker'] = df.max()\n",
    "    boxplot['means'] = df.mean()\n",
    "    boxplot['region'] = pd.unique(df.region)[0]\n",
    "\n",
    "    frames.append(boxplot)\n",
    "\n",
    "box = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# titel and histogram\n",
    "# scatterplot\n",
    "source = ColumnDataSource({'x': list(zip(melted.region, melted.jc_class)),\n",
    "                           'y': melted.score,\n",
    "                           'id': melted.tile,\n",
    "                           'colors': melted.colors})\n",
    "hover = HoverTool(tooltips=[('Region/Class', '@x'),\n",
    "                            ('Tile', '@id'),\n",
    "                            ('JC-Score', '@y'),])\n",
    "factors = [(reg, cls) \n",
    "           for reg in pd.unique(melted.region) \n",
    "           for cls in pd.unique(melted.jc_class)]\n",
    "\n",
    "scatter = figure(x_range=FactorRange(*factors), plot_width=950, plot_height=600,\n",
    "              tools=[hover, 'pan', 'wheel_zoom', 'save', 'reset', 'box_zoom'],\n",
    "              title=\"Jaccard score per forest cover class\")\n",
    "\n",
    "scatter.x(x=jitter('x', width=0.6, range=scatter.x_range), y='y', color='colors', source=source)\n",
    "\n",
    "scatter.xgrid.grid_line_color = None\n",
    "scatter.xaxis.axis_label = \"Region/Class\"\n",
    "scatter.yaxis.axis_label = \"Jaccard score\"\n",
    "scatter.y_range.start = -0.01\n",
    "\n",
    "# boxplot\n",
    "source = ColumnDataSource({'x': list(zip(box.region, box.index)),\n",
    "                           'q1': box.q1,\n",
    "                           'q2': box.q2,\n",
    "                           'q3': box.q3,\n",
    "                           'iqr': box.iqr,\n",
    "                           'lw': box.min_whisker,\n",
    "                           'uw': box.max_whisker,\n",
    "                           'means': box.means})\n",
    "hover = HoverTool(tooltips=[(\"Region/Class\", \"@x\"),\n",
    "                            (\"Q1\", \"@q1\"),\n",
    "                            (\"Q2\", \"@q2\"),\n",
    "                            (\"Q3\", \"@q3\"),\n",
    "                            (\"IQR\", \"@iqr\"),\n",
    "                            (\"lWhisker\", \"@lw\"),\n",
    "                            (\"uWhisker\", \"@uw\"),\n",
    "                            (\"Mean\", \"@means\"),])\n",
    "\n",
    "plot = figure(x_range=scatter.x_range, y_range=scatter.y_range,\n",
    "              plot_width=950, plot_height=300,\n",
    "              tools=[hover, 'pan', 'wheel_zoom', 'save', 'reset', 'box_zoom'])\n",
    "\n",
    "# box\n",
    "plot.vbar(x='x', width=0.7, bottom='q1', top='q2',\n",
    "          line_color='black', fill_color='#f7f7f7', fill_alpha=0.7, source=source)\n",
    "plot.vbar(x='x', width=0.7, bottom='q2', top='q3',\n",
    "          line_color='black', fill_color='#67a9cf', fill_alpha=0.7, source=source)\n",
    "\n",
    "# whiskers\n",
    "plot.rect(x='x', y='lw', width=0.2, height=0.001,\n",
    "          line_color=\"black\", source=source)\n",
    "plot.rect(x='x', y='uw', width=0.2, height=0.001,\n",
    "          line_color=\"black\", source=source)\n",
    "\n",
    "# stems\n",
    "plot.segment(x0='x', y0='lw', x1='x', y1='q1',\n",
    "             line_color='black', source=source)\n",
    "plot.segment(x0='x', y0='q3', x1='x', y1='uw',\n",
    "             color='black', source=source)\n",
    "\n",
    "# mean cross\n",
    "plot.x(x='x', y='means', color='#ef8a62', size=10, source=source)\n",
    "\n",
    "plot.xgrid.grid_line_color = None\n",
    "plot.xaxis.axis_label = \"Region/Class\"\n",
    "plot.yaxis.axis_label = \"Jaccard score\"\n",
    "plot.y_range.start = -0.01\n",
    "\n",
    "# display plots\n",
    "show(gridplot([[scatter],[plot]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[<a id=\"cit-Hansen2013\" href=\"#call-Hansen2013\">1</a>] C. M., V. P., Moore R. <em>et al.</em>, ``_High-Resolution Global Maps of 21st-Century Forest Cover Change_'', Science, vol. 342, number 6160, pp. 850--853, November 2013.\n",
    "\n",
    "[<a id=\"cit-Li2017\" href=\"#call-Li2017\">2</a>] Li Yan, Sulla-Menashe Damien, Motesharrei Safa <em>et al.</em>, ``_Inconsistent estimates of forest cover change in China between 2000 and 2013 from multiple datasets: differences in parameters, spatial resolution, and definitions_'', Scientific Reports, vol. 7, number 8748, pp. , August 2017.\n",
    "\n",
    "[<a id=\"cit-Hansen2013a\" href=\"#call-Hansen2013a\">3</a>] C. M., V. P., Moore R. <em>et al.</em>, ``_Supplementary Materials for: High-Resolution Global Maps of 21st-Century Forest Cover Change_'', Sciene, vol. 342, number 6160, pp. 1--32, November 2013.  [online](http://science.sciencemag.org/content/suppl/2013/11/14/342.6160.850.DC1)\n",
    "\n",
    "[<a id=\"cit-Tropek2014\" href=\"#call-Tropek2014\">4</a>] Tropek Robert, Sedl{\\'{a}}{\\v{c}}ek Ond{\\v{r}}ej, Beck Jan <em>et al.</em>, ``_Comment on High-resolution global maps of 21st-century forest cover change_'', Science, vol. 344, number 981, pp. ,  2014.\n",
    "\n",
    "[<a id=\"cit-Bellot2014\" href=\"#call-Bellot2014\">5</a>] Bellot Franz-Fabian, Bertram Mathias, Navratilb Peter <em>et al.</em>, ``_The high-resolution global map of 21st-century forest cover change from the University of Maryland (Hansen Map) is hugely overestimating deforestation in Indonesia_'', FORCLIME Press release, vol. , number , pp. ,  2014.  [online](http://www.forclime.org/documents/press_release/FORCLIME_Overestimation%20of%20Deforestation.pdf)\n",
    "\n",
    "[<a id=\"cit-Li2017a\" href=\"#call-Li2017a\">6</a>] Li Yan, Sulla-Menashe Damien, Motesharrei Safa <em>et al.</em>, ``_Supplementary Information for Inconsistent estimates of forest cover change in China between 2000 and 2013 from multiple datasets_'', Scientific reports, vol. 7, number 8748, pp. , August 2017.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "lit.bib",
   "cite_by": "number",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
