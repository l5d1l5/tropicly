{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DIRS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4dfd9fc24297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# init Logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mformater\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(asctime)s %(levelname)s: %(message)s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%d/%m/%y %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'jupyter.log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DIRS' is not defined"
     ]
    }
   ],
   "source": [
    "# third party libs\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import logging\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "from bokeh.transform import jitter\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import HoverTool, FactorRange\n",
    "from bokeh.plotting import output_notebook, show, figure, ColumnDataSource\n",
    "\n",
    "# custom libs\n",
    "from src.utils import (get_data_dir,)\n",
    "                    \n",
    "\n",
    "directories = \"\"\"\n",
    "data\n",
    "data.log\n",
    "data.tmp\n",
    "data.ana\n",
    "data.proc\n",
    "data.core\n",
    "data.core.ifl\n",
    "data.core.gfc\n",
    "data.core.soil\n",
    "data.core.gl30\n",
    "data.core.esvd\n",
    "data.core.biomass\n",
    "data.auxiliary\n",
    "data.auxiliary.masks\n",
    "\"\"\"\n",
    "\n",
    "for item in directories.split():\n",
    "    path = os.sep.join(item.split('.'))\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "# init Logging\n",
    "formater = logging.Formatter('%(asctime)s %(levelname)s: %(message)s', '%d/%m/%y %H:%M:%S')\n",
    "handler = logging.FileHandler(str(DIRS.log / 'jupyter.log'), 'a+')\n",
    "handler.setLevel(logging.DEBUG)\n",
    "handler.setFormatter(formater)\n",
    "\n",
    "LOGGER = logging.getLogger('Master')\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "LOGGER.addHandler(handler)\n",
    "\n",
    "# Convenient access to data directory, is a namedtuple with folder names as attributes\n",
    "DIRS = get_data_dir(str(Path('data').resolve()))\n",
    "\n",
    "# Many functions of the processing pipeline are multi-threaded this attribute controls\n",
    "# max number of threads\n",
    "THREADLIMIT = 12\n",
    "\n",
    "SPOOF_AGENT = {'headers': {'User-Agent': \"Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11\"}}\n",
    "\n",
    "WGS84 = {'init': 'epsg:4326'}\n",
    "\n",
    "# force bokeh plot output to jupyter notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Forest Change\n",
    "[**Global Forest Change 2000-2012 Version 1.0**](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.0.html) (GFC) is the first high resolution dataset that provides a comprehensive view on the annual global forest cover change between 2000 and 2012 \\cite{Hansen2013, Li2017}. The initial GFC dataset released by Hansen et al. is extended by recent releases which encompass the annual forest cover changes between [2000-2013 (Version 1.1)](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.1.html), [2000-2014 (Version 1.2)](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.2.html), [2000-2015 (Version 1.3)](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.3.html) and [2000-2016 (Version 1.4)](https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.4.html) respectively. All versions of this dataset has in common, that they are derived from growing season imagery captured by the remote sensing satellite Landsat 7 Enhanced Thematic Mapper Plus (ETM+) at a spatial resolution of 30 meters per pixel \\cite{Hansen2013a}. On the satellite imagery a time-series spectral metrics analysis is applied to gather the global forest extent at 2000 as well as the annual forest loss and gain. Hence, GFC comprises three independent data layers  tree cover, annually forest loss and  forest gain divided into 10x10 degree tiles by the geodetic coordinate system *World Geodetic System 1984* (EPSG:4326). Furthermore, across the provided layers the pixel data is coded in unsigned 8 bit integers. Hansen et al. defined trees as all vegetation taller than 5 meters for their study. Forest loss is defined as a stand displacement disturbance leading from a forest state to a non forest-state. To compute this losses \n",
    "\n",
    "[Global Forest Watch](http://www.globalforestwatch.org/) interactive map\n",
    "\n",
    "- Flow general what is gfc then detailed info monitoring method, details of the different layers, how certain is the info\n",
    "- trees defined as all vegetation higher than 5 meters Hansen2013, Hansen2013a\n",
    "- forest loss defined as a stand displacement disturbance (> x% crown cover to 0% crown cover)  Hansen2013, Hansen2013a\n",
    "- monitored by a reference percent tree cover stratum Hansen2013, Hansen2013a\n",
    "- forest degeneration for example selective removals btw. all impacts on forest which are not lead to a non forest state are not considered Hansen2013a\n",
    "- term forest refer to tree cover Hansen2013a\n",
    "- gain is the inverse of loss e.g. the change of a non forest state to forest (crown cover densities >50%)\n",
    "- Forest loss detection is less uncertain then gain detection (loss is more reliable) Li2017\n",
    "- Gain is a more gradual and ecological complex process, signal is more difficult to detect Li2017\n",
    "- Li2017 compares 4 different forest cover change products on their performance to estimate loss and gain patterns in china\n",
    "- at the end show a example picture of the data\n",
    "\n",
    "\n",
    "\\cite{Hansen2013}\n",
    "\\cite{Hansen2013a}\n",
    "\\cite{Tropek2014}\n",
    "\\cite{Bellot2014}\n",
    "\\cite{Li2017}\n",
    "\\cite{Li2017a}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hansen preview](img/hansen_preview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data source URL\n",
    "head = 'http://commondatastorage.googleapis.com/earthenginepartners-hansen/GFC2013/'\n",
    "# files to download from source url\n",
    "tails = 'treecover2000.txt gain.txt lossyear.txt'.split()\n",
    "\n",
    "data_urls = []\n",
    "for tail in tails:\n",
    "    content = download(head + tail)\n",
    "    data_urls += content.decode('utf-8').splitlines()\n",
    "\n",
    "to_download = []\n",
    "for url in data_urls:\n",
    "    lat_lon = re.search(r'(\\d{2}\\w_\\d{3}\\w)(?=\\.tif)', url).groups()[0]\n",
    "    lat = orientation_to_int(lat_lon.split('_')[0])\n",
    "    if -20 <= lat <= 30:\n",
    "        to_download.append(url)\n",
    "\n",
    "threads = []\n",
    "for idx, url in enumerate(to_download):\n",
    "    if len(threads) == THREADLIMIT:\n",
    "        [thread.join() for thread in threads]\n",
    "        threads = []\n",
    "        clear_output()\n",
    "        print('Downloaded {} of {}'.format(idx, len(to_download)))\n",
    "        \n",
    "    path = str(DIRS.gfc / url.split('/')[-1])\n",
    "    thread = threading.Thread(target=worker, args=(url, path))\n",
    "    thread.start()\n",
    "    threads.append(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GlobalLand30\n",
    "[GlobLand30](http://www.globallandcover.com/GLC30Download/index.aspx) (GL30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Chen preview](img/chen_preview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aboveground live woody biomass density\n",
    "[Aboveground Live Woody Biomass Density](http://data.globalforestwatch.org/datasets/8f93a6f94a414f9588ce4657a39c59ff_1) (LWBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://data.globalforestwatch.org/datasets/8f93a6f94a414f9588ce4657a39c59ff_1.geojson'\n",
    "path = str(DIRS.masks / 'biomass.geojson')\n",
    "\n",
    "content = download(url)\n",
    "write_binary(content, path)\n",
    "\n",
    "biomass_mask = gpd.read_file(path)\n",
    "to_download = list(biomass_mask.download) + list(biomass_mask.confidence) \n",
    "\n",
    "threads = []\n",
    "for idx, url in enumerate(to_download):\n",
    "    if len(threads) == THREADLIMIT:\n",
    "        [thread.join() for thread in threads]\n",
    "        threads = []\n",
    "        clear_output()\n",
    "        print('Downloaded {} of {}'.format(idx, len(to_download)))\n",
    "    \n",
    "    path = str(DIRS.biomass / url.split('/')[-1])\n",
    "    thread = threading.Thread(target=worker, args=(url, path), kwargs=SPOOF_AGENT)\n",
    "    thread.start()\n",
    "    threads.append(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global soil organic carbon map\n",
    "[The Global Soil Organic Carbon Map](http://www.fao.org/world-soil-day/global-soil-organic-carbon-map/en/) (GSOCmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download broken fix it please\n",
    "url = 'https://unfao-my.sharepoint.com/personal/guillermo_olmedo_fao_org/_layouts/15/guestaccess.aspx?docid=059b0b724d08a42e4931c35cff99a15c1&authkey=AcRgiPkRQvm_kuJb-K0-e2o&e=e70096969c4e4ce084d2ee1d1ca8bc44'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.soil / 'GSOCmap.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecosystem service valuation database\n",
    "[Ecosystem Service Valuation Database](https://www.es-partnership.org/services/data-knowledge-sharing/ecosystem-service-valuation-database/) (ESVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.es-partnership.org/wp-content/uploads/2016/06/ESVD-TEEB-database.xls'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.esvd / url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intact Forest Landscapes\n",
    "[Intact Forest Landscapes](http://intactforests.org/index.html) (IFL2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://intactforests.org/shp/IFL_2000.zip'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.ifl / url.split('/')[-1]))\n",
    "\n",
    "zipfile.ZipFile(str(DIRS.ifl / url.split('/')[-1])).extractall(str(DIRS.ifl))\n",
    "os.remove(str(DIRS.ifl / url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Natural Earth Data](http://www.naturalearthdata.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_populated_places.zip'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.masks / url.split('/')[-1]))\n",
    "\n",
    "zipfile.ZipFile(str(DIRS.masks / url.split('/')[-1])).extractall(str(DIRS.masks))\n",
    "os.remove(str(DIRS.masks / url.split('/')[-1]))\n",
    "\n",
    "url = 'http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries.zip'\n",
    "\n",
    "content = download(url, **SPOOF_AGENT)\n",
    "write_binary(content, str(DIRS.masks / url.split('/')[-1]))\n",
    "\n",
    "zipfile.ZipFile(str(DIRS.masks / url.split('/')[-1])).extractall(str(DIRS.masks))\n",
    "os.remove(str(DIRS.masks / url.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GFC mask\n",
    "gfc = sorted(DIRS.gfc.glob('*.tif'))\n",
    "\n",
    "data_len = int(len(gfc)/3)\n",
    "\n",
    "kwargs = {\n",
    "    'gain': [i.name for i in gfc[:data_len]],\n",
    "    'loss': [i.name for i in gfc[data_len:2*data_len]],\n",
    "    'cover': [i.name for i in gfc[2*data_len:]],\n",
    "}\n",
    "\n",
    "gfc_mask = tile_index(gfc[:data_len], WGS84, **kwargs)\n",
    "gfc_mask.to_file(str(DIRS.masks / 'gfc_mask.shp'))\n",
    "gfc_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GL30 mask\n",
    "gl30 = sorted(DIRS.gl30.glob('*.tif'), key=lambda key: (key.name[7:11], key.name[0:6]))\n",
    "\n",
    "exclude = 'n01_00 s01_00 s01_10 s01_15 s01_20 s60_00 s60_05 s60_10 s60_15 n53_00'.split()\n",
    "gl30 = [item for item in gl30 if item.name[0:6] not in exclude]\n",
    "data_len = int(len(gl30)/2)\n",
    "\n",
    "kwargs = {\n",
    "    'gl30_00': [i.name for i in gl30[:data_len]],\n",
    "    'gl30_10': [i.name for i in gl30[data_len:]],\n",
    "    'key': [i.name[0:6] for i in gl30[:data_len]]\n",
    "}\n",
    "\n",
    "gl30_mask = tile_index(gl30[data_len:], WGS84, **kwargs)\n",
    "gl30_mask.to_file(str(DIRS.masks / 'gl30_mask.shp'))\n",
    "gl30_mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Biomass mask\n",
    "biomass = gpd.read_file(str(DIRS.masks / 'biomass.geojson'))\n",
    "biomass_mask = biomass.drop(biomass.columns[[0, 1, 4, 5]], axis=1)\n",
    "biomass_mask.rename(columns={'download': 'biomass'}, inplace=True)\n",
    "\n",
    "for idx, row in biomass_mask.iterrows():\n",
    "    biomass = row.biomass.split('/')[-1]\n",
    "    confidence = row.confidence.split('/')[-1]\n",
    "    \n",
    "    biomass_mask.at[idx, 'biomass'] = biomass\n",
    "    biomass_mask.at[idx, 'confidence'] = confidence\n",
    "\n",
    "biomass_mask.to_file(str(DIRS.masks / 'biomass_mask.shp'))\n",
    "biomass_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raster alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gl30_mask = gpd.read_file(str(DIRS.masks / 'gl30_mask.shp'))\n",
    "gfc_mask = gpd.read_file(str(DIRS.masks / 'gfc_mask.shp'))\n",
    "biomass_mask = gpd.read_file(str(DIRS.masks / 'biomass_mask.shp'))\n",
    "\n",
    "intersect = gpd.overlay(gfc_mask, gl30_mask, how='intersection')\n",
    "intersect = gpd.overlay(intersect, biomass_mask, how='intersection')\n",
    "\n",
    "threads = []\n",
    "for key, values in intersect.groupby(by='key', sort=False):\n",
    "    if len(threads) == THREADLIMIT:\n",
    "        [thread.join() for thread in threads]\n",
    "        threads = []\n",
    "    \n",
    "    to_reproject = [\n",
    "        str(DIRS.gl30 / name)\n",
    "        for name in list(*zip(set(values.gl30_10), set(values.gl30_00)))\n",
    "    ]\n",
    "    to_reproject.append(str(DIRS.soil / 'GSOCmapV1.1.tif'))\n",
    "    to_merge = [\n",
    "        [str(DIRS.gfc / name) for name in set(values.cover)],\n",
    "        [str(DIRS.gfc / name) for name in set(values.loss)],\n",
    "        [str(DIRS.gfc / name) for name in set(values.gain)],\n",
    "        [str(DIRS.biomass / name) for name in set(values.biomass)],\n",
    "        [str(DIRS.biomass / name) for name in set(values.confidence)],\n",
    "    ]\n",
    "    generic_name = '{}.tif'.format(key)\n",
    "    \n",
    "    thread = threading.Thread(target=worker,\n",
    "                              args=(to_reproject, WGS84, to_merge, str(DIRS.proc), generic_name))\n",
    "    thread.start()\n",
    "    threads.append(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping and masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = defaultdict(list)\n",
    "regex = re.compile(r'.*(?P<key>(?:n|s)\\d{2}_\\d{2}).*', re.I)\n",
    "\n",
    "for path in DIRS.proc.glob('*.tif'):\n",
    "    match = regex.match(str(path))\n",
    "    files[match.group('key')].append(path)\n",
    "    files[match.group('key')] = sorted(files[match.group('key')])\n",
    "\n",
    "threads = []\n",
    "features = []\n",
    "polygons = []\n",
    "length = len(files)\n",
    "idx = 0\n",
    "for key, values in files.items():\n",
    "    if len(threads) == THREADLIMIT:\n",
    "        [thread.join() for thread in threads]\n",
    "        threads = []\n",
    "        \n",
    "        clear_output()\n",
    "        ratio = round((idx / length) * 100, 2)\n",
    "        print('Processed {} % of {} %'.format(ratio, 100))\n",
    "    \n",
    "    bounds, profile = fetch_metadata(values[0], 'bounds', 'profile')\n",
    "    bounds = round_bounds(bounds)\n",
    "\n",
    "    thread = threading.Thread(target=clip_worker, args=(values, bounds, profile, str(DIRS.proc),))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "    key = int_to_orient(bounds.left, bounds.top)\n",
    "    feature = dict([dispatch_name('{0[0]}_{0[1]}'.format(item.name.split('_')), key, idx)\n",
    "                    for idx, item in enumerate(values)])\n",
    "    feature['key'] = key\n",
    "    features.append(feature)\n",
    "    polygons.append(polygon_from(bounds))\n",
    "    \n",
    "    idx += 1\n",
    "\n",
    "geometry = gpd.GeoSeries(polygons)\n",
    "df = pd.DataFrame(features)\n",
    "layer = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "layer.crs = WGS84\n",
    "\n",
    "layer.to_file(str(DIRS.masks / 'final_mask.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = gpd.read_file(str(DIRS.masks / 'ne_10m_admin_0_countries.shp'))\n",
    "tiles = gpd.read_file(str(DIRS.masks / 'final_mask.shp'))\n",
    "tiles.crs = WGS84\n",
    "\n",
    "aio = countries.cx[:,-23:23]\n",
    "aio = aio[['REGION_UN', 'geometry']]\n",
    "continents = aio.dissolve(by='REGION_UN')\n",
    "\n",
    "layer = gpd.sjoin(tiles, continents, how='left', op='intersects')\n",
    "layer.to_file(str(DIRS.masks / 'final_region_mask.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = gpd.read_file(str(DIRS.masks / 'final_region_mask.shp'))\n",
    "q = queue.Queue()\n",
    "threads = []\n",
    "for idx, val in mask.iterrows():\n",
    "    if len(threads) == 4:\n",
    "        [thread.join() for thread in threads]\n",
    "        threads = []\n",
    "        clear_output()\n",
    "        print('{}% of 100%'.format(((idx+1)/len(mask))*100))\n",
    "    \n",
    "    thread = threading.Thread(target=worker, args=(DIRS.proc/val.gl30_00, DIRS.proc/val.cover, q, val.key, val.index_righ))\n",
    "    thread.start()\n",
    "    threads.append(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = []\n",
    "while not q.empty():\n",
    "    vals.append(q.get())\n",
    "\n",
    "df = pd.DataFrame(vals)\n",
    "df.columns = ['tile', 'region', 'jc0', 'smc0', 'jc10', 'smc10', 'jc20', 'smc20', 'jc30', 'smc30']\n",
    "df.to_csv(DIRS.ana/'class_harmon_wet.csv', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = pd.read_csv(str(DIRS.ana / 'class_harmon_wet.csv'))\n",
    "\n",
    "# initial data clean up\n",
    "src.rename(columns=lambda x: x.upper() if x[:2] == 'jc' else x, inplace=True)\n",
    "src.drop('smc0 smc10 smc20 smc30'.split(), axis=1, inplace=True)\n",
    "src.drop(src.columns[0], axis=1, inplace=True)\n",
    "src.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "# scatterplot data prep\n",
    "melted = src.melt(id_vars='tile region'.split(), var_name='jc_class', value_name='score')\n",
    "melted['colors'] = '#ffffff'\n",
    "melted.loc[melted['jc_class'] == 'JC0', 'colors'] = '#e66101'\n",
    "melted.loc[melted['jc_class'] == 'JC10', 'colors'] = '#fdb863'\n",
    "melted.loc[melted['jc_class'] == 'JC20', 'colors'] = '#b2abd2'\n",
    "melted.loc[melted['jc_class'] == 'JC30', 'colors'] = '#5e3c99'\n",
    "melted.sort_values(by=['region', 'jc_class'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# boxplot data prep\n",
    "frames = []\n",
    "for key, df in src.groupby('region'):\n",
    "    boxplot = df.quantile(q=(0.25, 0.5, 0.75)).T\n",
    "    boxplot.columns = ['q1', 'q2', 'q3']\n",
    "    boxplot['iqr'] = boxplot.q3 - boxplot.q1\n",
    "    boxplot['tukey_lower_whisker'] = boxplot.q1 - 1.5 * boxplot.iqr\n",
    "    boxplot['tukey_upper_whisker'] = boxplot.q3 + 1.5 * boxplot.iqr\n",
    "    boxplot['q_lower_whisker'] = df.quantile(q=0.025)\n",
    "    boxplot['q_upper_whisker'] = df.quantile(q=0.975)\n",
    "    boxplot['min_whisker'] = df.min()\n",
    "    boxplot['max_whisker'] = df.max()\n",
    "    boxplot['means'] = df.mean()\n",
    "    boxplot['region'] = pd.unique(df.region)[0]\n",
    "\n",
    "    frames.append(boxplot)\n",
    "\n",
    "box = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# titel and histogram\n",
    "# scatterplot\n",
    "source = ColumnDataSource({'x': list(zip(melted.region, melted.jc_class)),\n",
    "                           'y': melted.score,\n",
    "                           'id': melted.tile,\n",
    "                           'colors': melted.colors})\n",
    "hover = HoverTool(tooltips=[('Region/Class', '@x'),\n",
    "                            ('Tile', '@id'),\n",
    "                            ('JC-Score', '@y'),])\n",
    "factors = [(reg, cls) \n",
    "           for reg in pd.unique(melted.region) \n",
    "           for cls in pd.unique(melted.jc_class)]\n",
    "\n",
    "scatter = figure(x_range=FactorRange(*factors), plot_width=950, plot_height=600,\n",
    "              tools=[hover, 'pan', 'wheel_zoom', 'save', 'reset', 'box_zoom'],\n",
    "              title=\"Jaccard score per forest cover class\")\n",
    "\n",
    "scatter.x(x=jitter('x', width=0.6, range=scatter.x_range), y='y', color='colors', source=source)\n",
    "\n",
    "scatter.xgrid.grid_line_color = None\n",
    "scatter.xaxis.axis_label = \"Region/Class\"\n",
    "scatter.yaxis.axis_label = \"Jaccard score\"\n",
    "scatter.y_range.start = -0.01\n",
    "\n",
    "# boxplot\n",
    "source = ColumnDataSource({'x': list(zip(box.region, box.index)),\n",
    "                           'q1': box.q1,\n",
    "                           'q2': box.q2,\n",
    "                           'q3': box.q3,\n",
    "                           'iqr': box.iqr,\n",
    "                           'lw': box.min_whisker,\n",
    "                           'uw': box.max_whisker,\n",
    "                           'means': box.means})\n",
    "hover = HoverTool(tooltips=[(\"Region/Class\", \"@x\"),\n",
    "                            (\"Q1\", \"@q1\"),\n",
    "                            (\"Q2\", \"@q2\"),\n",
    "                            (\"Q3\", \"@q3\"),\n",
    "                            (\"IQR\", \"@iqr\"),\n",
    "                            (\"lWhisker\", \"@lw\"),\n",
    "                            (\"uWhisker\", \"@uw\"),\n",
    "                            (\"Mean\", \"@means\"),])\n",
    "\n",
    "plot = figure(x_range=scatter.x_range, y_range=scatter.y_range,\n",
    "              plot_width=950, plot_height=300,\n",
    "              tools=[hover, 'pan', 'wheel_zoom', 'save', 'reset', 'box_zoom'])\n",
    "\n",
    "# box\n",
    "plot.vbar(x='x', width=0.7, bottom='q1', top='q2',\n",
    "          line_color='black', fill_color='#f7f7f7', fill_alpha=0.7, source=source)\n",
    "plot.vbar(x='x', width=0.7, bottom='q2', top='q3',\n",
    "          line_color='black', fill_color='#67a9cf', fill_alpha=0.7, source=source)\n",
    "\n",
    "# whiskers\n",
    "plot.rect(x='x', y='lw', width=0.2, height=0.001,\n",
    "          line_color=\"black\", source=source)\n",
    "plot.rect(x='x', y='uw', width=0.2, height=0.001,\n",
    "          line_color=\"black\", source=source)\n",
    "\n",
    "# stems\n",
    "plot.segment(x0='x', y0='lw', x1='x', y1='q1',\n",
    "             line_color='black', source=source)\n",
    "plot.segment(x0='x', y0='q3', x1='x', y1='uw',\n",
    "             color='black', source=source)\n",
    "\n",
    "# mean cross\n",
    "plot.x(x='x', y='means', color='#ef8a62', size=10, source=source)\n",
    "\n",
    "plot.xgrid.grid_line_color = None\n",
    "plot.xaxis.axis_label = \"Region/Class\"\n",
    "plot.yaxis.axis_label = \"Jaccard score\"\n",
    "plot.y_range.start = -0.01\n",
    "\n",
    "# display plots\n",
    "show(gridplot([[scatter],[plot]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[<a id=\"cit-Hansen2013\" href=\"#call-Hansen2013\">1</a>] C. M., V. P., Moore R. <em>et al.</em>, ``_High-Resolution Global Maps of 21st-Century Forest Cover Change_'', Science, vol. 342, number 6160, pp. 850--853, November 2013.\n",
    "\n",
    "[<a id=\"cit-Li2017\" href=\"#call-Li2017\">2</a>] Li Yan, Sulla-Menashe Damien, Motesharrei Safa <em>et al.</em>, ``_Inconsistent estimates of forest cover change in China between 2000 and 2013 from multiple datasets: differences in parameters, spatial resolution, and definitions_'', Scientific Reports, vol. 7, number 8748, pp. , August 2017.\n",
    "\n",
    "[<a id=\"cit-Hansen2013a\" href=\"#call-Hansen2013a\">3</a>] C. M., V. P., Moore R. <em>et al.</em>, ``_Supplementary Materials for: High-Resolution Global Maps of 21st-Century Forest Cover Change_'', Sciene, vol. 342, number 6160, pp. 1--32, November 2013.  [online](http://science.sciencemag.org/content/suppl/2013/11/14/342.6160.850.DC1)\n",
    "\n",
    "[<a id=\"cit-Tropek2014\" href=\"#call-Tropek2014\">4</a>] Tropek Robert, Sedl{\\'{a}}{\\v{c}}ek Ond{\\v{r}}ej, Beck Jan <em>et al.</em>, ``_Comment on High-resolution global maps of 21st-century forest cover change_'', Science, vol. 344, number 981, pp. ,  2014.\n",
    "\n",
    "[<a id=\"cit-Bellot2014\" href=\"#call-Bellot2014\">5</a>] Bellot Franz-Fabian, Bertram Mathias, Navratilb Peter <em>et al.</em>, ``_The high-resolution global map of 21st-century forest cover change from the University of Maryland (Hansen Map) is hugely overestimating deforestation in Indonesia_'', FORCLIME Press release, vol. , number , pp. ,  2014.  [online](http://www.forclime.org/documents/press_release/FORCLIME_Overestimation%20of%20Deforestation.pdf)\n",
    "\n",
    "[<a id=\"cit-Li2017a\" href=\"#call-Li2017a\">6</a>] Li Yan, Sulla-Menashe Damien, Motesharrei Safa <em>et al.</em>, ``_Supplementary Information for Inconsistent estimates of forest cover change in China between 2000 and 2013 from multiple datasets_'', Scientific reports, vol. 7, number 8748, pp. , August 2017.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "lit.bib",
   "cite_by": "number",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
